{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algebraic graph theory\n",
    "Algebraic graph theory is concerned with the study of graphs through several related matrices.\n",
    "We then need to understand how arrays are represented and can be manipulated with Python using the library NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array creation\n",
    "You can create a numpy array from a Python list or tuple using the  `array ` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([2,3,4])\n",
    "print(\"a=\", a)\n",
    "print(\"Dimension of a:\", a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `array ` transforms lists of lists into two-dimensional arrays, i.e., matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([[1.5,2,3], [4,5,6]])\n",
    "print(b)\n",
    "print(\"Dimension of b:\", b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function  `zeros ` creates an array full of zeros, the function  `ones ` creates an array full of ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.zeros((3, 4))) # tuple (3,4) is the shape of the zero array to be created\n",
    "print(np.ones((2,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can create arrays whose elements space in a given range using  `arange `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first two arguments are the starting point (included) and the ending point (excluded)\n",
    "# the third argument is the step-size\n",
    "np.arange(10, 30, 5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or using the function `linspace` that receives as an argument the number of elements that we want to obtain in the given range, instead of the step size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first two arguments are the starting and ending point (both included!), \n",
    "# third argument is the number of elements\n",
    "np.linspace(0, 2, 9 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize, numpy `ndarray` can represent arrays of any dimension but we will restrict to dimension 1 (vectors) and 2 (matrices). One-dimensional arrays are printed as rows, bidimensionals as matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.arange(): default start value is 0, default step size is 1\n",
    "a = np.arange(6)                         # 1d array\n",
    "print(\"a:\", a, \"\\n\")\n",
    "b = np.arange(12).reshape(4,3)           # 2d array\n",
    "print(\"b: \\n\",b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic operations\n",
    "Arithmetic operators on arrays apply element-wise. A new array is created and filled with the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([20,30,40,50])\n",
    "print(\"a=\",a)\n",
    "# np.arange(): default start value is 0, default step size is 1, \n",
    "# so b = [0,1,2,3]\n",
    "b = np.arange(4)\n",
    "print(\"b=\", b)\n",
    "c = a-b\n",
    "print(\"c=a-b =\", c)\n",
    "# ** denotes the second power ^2\n",
    "print(\"b^2=\", b**2) \n",
    "print(\"10 sin(a)=\", 10*np.sin(a))\n",
    "print(\"a<35:\", a<35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The product operator `*` operates element-wise in NumPy arrays. \n",
    "The matrix product can be performed using the `@` operator or the `dot` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two numpy arrays starting from lists of lists\n",
    "A = np.array( [[1,1],   \n",
    "               [0,1]] )\n",
    "B = np.array( [[2,0],\n",
    "               [3,4]] )\n",
    "print(\"A*B= \\n\", A * B, \"\\n\")                # elementwise product\n",
    "print(\"A@B= \\n\", A @ B, \"\\n\")                # matrix product\n",
    "print(\"A.dot(B)=\\n\", A.dot(B))               # another matrix product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy provides familiar mathematical functions such as sin, cos, and exp. In NumPy, these are called “universal functions”(`ufunc`). Within NumPy, these functions operate elementwise on an array, producing an array as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.arange(3) # B=[0,1,2]\n",
    "np.exp(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral graph theory\n",
    "We will explore several notions from spectral graph theory by analysing the following graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "G = nx.DiGraph()\n",
    "nx.add_cycle(G,[1,2,3,4])\n",
    "nx.add_cycle(G,[4,3,2,1])\n",
    "\n",
    "nx.draw_circular(G, with_labels=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we construct the `weight matrix` $W$ (called also `adjacency matrix` in NetworkX), the diagonal matrix $D$, and the normalized adjacency matrix $P$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "# convert W to a numpy array\n",
    "W = W.toarray()\n",
    "print(\"W:\",W, \"\\n\")\n",
    "degrees = np.sum(W,axis=1)\n",
    "print(\"Degrees:\",degrees, \"\\n\")\n",
    "D = np.diag(degrees)\n",
    "print(\"D: \\n\",D,\"\\n\")\n",
    "# P = D^(-1) W\n",
    "P = np.linalg.inv(D) @ W\n",
    "print(\"P: \\n\",P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the powers of the matrix $W$. Powers of $W$ have a useful interpretation in a unweighted (di)graphs, namely, $(W^n)_{ij}$ equals the number of walks of length $n$ from $i$ to $j$.\n",
    "\n",
    "The interpretation can be extended to weighted graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute W^2\n",
    "power = W\n",
    "power = power @ W\n",
    "print(\"W^2 =\", power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute W^3\n",
    "power = power @ W\n",
    "print(\"W^3 =\", power)\n",
    "\n",
    "# Note that we compute P^3 by using P^2 to save computational time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute W^11\n",
    "for n in range(3,11):\n",
    "    power = power @ W\n",
    "print(\"W^11 =\", power)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The powers of $W$ still contain zero elements. Why?\n",
    "\n",
    "The reason is that the graph $G$ is periodic, as can be easily verified. There are no closed walks of odd length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Is G aperiodic:\",nx.is_aperiodic(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us modify the graph to make it aperiodic, and compute again the powers of $W$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2 = nx.DiGraph()\n",
    "nx.add_cycle(G2,[1,2,3,4])\n",
    "nx.add_cycle(G2,[4,3,2,1])\n",
    "G2.add_edge(1,3)\n",
    "G2.add_edge(3,1)\n",
    "\n",
    "print(\"Is G2 aperiodic:\",nx.is_aperiodic(G2))\n",
    "\n",
    "nx.draw_circular(G2, with_labels=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = nx.adjacency_matrix(G2)\n",
    "W2 = W2.toarray()\n",
    "\n",
    "degrees = np.sum(W2,axis=1)\n",
    "print(\"Degrees\",degrees, \"\\n\")\n",
    "\n",
    "D2 = np.diag(degrees)\n",
    "print(\"D2: \\n\",D2,\"\\n\")\n",
    "\n",
    "P2 = np.linalg.inv(D2) @ W2\n",
    "print(\"P2: \\n\",P2,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: what is the smallest power of $W$ that does not have null elements?\n",
    "\n",
    "**Hint**: exploit the fact that in unweighted (di)graphs $(W^n)_{ij}$ is the number of walks between $i$ and $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = G2.number_of_nodes()\n",
    "index = 1\n",
    "\n",
    "power = W2\n",
    "\n",
    "while nx.is_aperiodic(G2):\n",
    "    if np.count_nonzero(power) == N*N:\n",
    "        print(\"The smallest power of W with all non-zero elements is:\", index)\n",
    "        break\n",
    "    else:\n",
    "        index += 1\n",
    "        power = power @ W2\n",
    "        \n",
    "print(power)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also observe that $G$ is bipartite, while $G_2$ is not. To this end, we exploit the notion of **coloring**.\n",
    "\n",
    "A coloring is a function $\\phi$ that assigns to every node $n$ a color $\\phi(n)$ with the property that, for every pair of adjacent nodes $\\{n,m\\}$, then $\\phi(n) != \\phi(m)$\n",
    " \n",
    "**Theorem**: a graph is bipartite if and only if there exists a 2-coloring (coloring with 2 colors) defined on the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We construct a coloring for the graph G\n",
    "color_map = []\n",
    "\n",
    "for node in range(G.number_of_nodes()):\n",
    "    if node % 2 == 1:\n",
    "        color_map.append('blue')\n",
    "    else: \n",
    "        color_map.append('red')\n",
    "        \n",
    "print(color_map)\n",
    "\n",
    "nx.draw_circular(G, node_color=color_map, with_labels=True)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $G$ admits a coloring, $G$ is bipartite.\n",
    "Note that a 2-coloring for $G_2$ does not exist, thus $G_2$ is not bipartite. Another way to see this, is by the following theorems.\n",
    "\n",
    "**Theorem 1**: an undirected graph is bipartite if and only if all circuits have even length.\n",
    "\n",
    "We can also leverage algebraic graph theory. The following result is a consequence of Perron-Frobenius theorem.\n",
    "\n",
    "**Theorem 2**: if a graph is bipartite, then the spectrum of its normalized adjacency matrix $P$ contains $-1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eig(P) returns the eigenvalues (in vector w)\n",
    "# and eigenvectors (in matrix v) of P\n",
    "\n",
    "w,v = np.linalg.eig(P)\n",
    "print(\"spectrum of P:\",w)\n",
    "\n",
    "w,v = np.linalg.eig(P2)\n",
    "print(\"spectrum of P2:\",w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theorem 1 states that $G$ is bipartite and $G_2$ is not. Theorem 2 only states that $G_2$ is not bipartite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trace of the n-th power of $W$ equals the number of circuits with length $n$ in the graph ($n\\ge2$).\n",
    "\n",
    "**Question**: what is the trace of $W^3$?\n",
    "\n",
    "To answer the question, let us plot again $G$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "nx.draw_circular(G, with_labels=True)\n",
    "\n",
    "plt.subplot(122)\n",
    "nx.draw_circular(G2, with_labels=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of length-3 circuits in G:\", np.matrix.trace(W@W@W))\n",
    "print(\"Number of length-3 circuits in G2:\", np.matrix.trace(W2@W2@W2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define a new graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(range(1,11))\n",
    "nx.add_cycle(G,[1,2,3])\n",
    "nx.add_cycle(G,[4,5,6])\n",
    "nx.add_cycle(G,[8,9,10])\n",
    "G.add_edges_from([(4,3), (3,8), (5,7), (7,7)])\n",
    "\n",
    "# define pos according to spring layout\n",
    "# to fix nodes' positions in all graph drawings.\n",
    "# spring_layout positions nodes using Fruchterman-Reingold force-directed algorithm.\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G,pos, with_labels=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invariant probability distributions\n",
    "In this section we show how to compute the invariant distributions of a graph.\n",
    "\n",
    "**Definition**: an `invariant distribution` $\\pi$ of a graph is a normalized eigenvector of $P'$ relative to eigenvalue $1$, i.e.,\n",
    "\n",
    "$$\n",
    "P' \\pi = \\pi, \\quad \\sum_i \\pi_i = 1\n",
    "$$ \n",
    "To do this, we first compute all eigenvalues and eigenvectors of $P'$ with function `np.linalg.eig()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = nx.adjacency_matrix(G)\n",
    "W = W.toarray()\n",
    "degrees = np.sum(W,axis=1)\n",
    "print(\"Degrees:\",degrees,\"\\n\")\n",
    "D = np.diag(degrees)\n",
    "print(\"D: \\n\",D,\"\\n\")\n",
    "# P = D^(-1) W\n",
    "P = np.linalg.inv(D) @ W\n",
    "print(\"P: \\n\",P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem**: if the graph is strongly connected, the eigenvalue 1 has multeplicity 1 (only one invariant distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the condensation graph of $G$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CG = nx.algorithms.components.condensation(G)\n",
    "nx.draw(CG, with_labels=True)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(dict(CG.nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph is not strongly connected, since the condensation graph has more than one node. \n",
    "\n",
    "To confirm this, we compute the spectrum of $P$, and show that the eigenvalue 1 has algebraic multeplicity greater than 1.\n",
    "\n",
    "**Remark**: multeplicity 1 of eigenvalue 1 does not imply strong connectedness of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eig(P.T) returns the eigenvalues (in vector w)\n",
    "# and eigenvectors (in matrix v) of P'\n",
    "w,v = np.linalg.eig(P.T)\n",
    "print(\"eigenvalues:\",w) # -> the 0th and 5th eigenvalues are 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two eigenvalues equal to 1 (in position 0 and 5 of `w`). We select the eigenvectors corresponding to the two occurrencies of eigenvalue 1 and we normalize them to obtain the two invariant distributions (`pi0` and `pi5`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we iterate over indices corresponding to eigenvalues 1\n",
    "# i.e. corresponding to entries of w that are equal 1:\n",
    "# for each index we extract the corresponding eigenvector in v\n",
    "# and normalize it\n",
    "\n",
    "# we use np.isclose() to compare eigenvalues to 1 to avoid\n",
    "# numerical precision errors\n",
    "for index in [i for i in range(len(G)) if np.isclose(w[i],1)]: \n",
    "    pi = v[:,index].real  # -> eigenvectors are complex but invariant distributions are real, so we convert pi to real\n",
    "    pi = pi/np.sum(pi) # normalization\n",
    "    print(\"pi\", index, \"=\", pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem**: the multeplicity of the eigenvalue 1 equals the number of trapping sets of the graph. Moreover, for every trapping set, there exists an invariant distribution (called extremal) whose support coincides with the node set of the trapping set.\n",
    "\n",
    "**Remark**: the extremal invariant distribution supported on a trapping set may be computed by computing the unique invariant distribution of the subgraph obtained by selecting the nodes of a trapping set.\n",
    "\n",
    "**Exercise**: Compute the extremal invariant distribution of $G$.\n",
    "\n",
    "1. Find the trapping sets of the graph\n",
    "2. For each trapping set, construct the corresponding induced subgraph\n",
    "3. Compute the P matrix of each induced subgraph and its invariant measure\n",
    "4. Map the obtained measures back to the original graph G (by adding zeros in the appropriate positions)\n",
    "\n",
    "**Hint**: use the methods introduced in the previous notebook, and the code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to now we have exploited the function `numpy.linalg.eig` to compute all the eigenvalues and eigenvectors of $P'$, and we have selected the leading ones. \n",
    "\n",
    "Another approach consists in applying an iterative method which converges to the leading eigenvector. This will be illustrated in the following weeks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network centralities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Node centralities measure the importance of the nodes of the network. Several notions of centrality may be defined, e.g.:\n",
    "\n",
    "**Degree centrality**: the centrality of a node is proportional to its degree. In digraphs, we can define both the indegree and the outdegree centrality. For instance, the indegree centrality is a measure of importance in Twitter network, since it measures the number of followers of every account.\n",
    "\n",
    "**Eigenvector centrality**: the eigenvector centrality generalizes the degree centrality. Instead of counting the number of neighbors as the degree centrality does, this centrality gives more importance to connections with more central nodes. Let $z$ denote the centrality. The eigenvector centrality satisfies\n",
    "\n",
    "$$\n",
    "z_i \\propto \\sum_{j} W_{ji}z_j\n",
    "$$\n",
    "\n",
    "By normalizing $z$, and taking the proportionality factor equal to dominant eigenvalue $\\lambda_W$, we obtain $\\lambda_W z = W'z$, i.e., $z$ is the dominant eigenvector of $W$, and has non-negative components because of Perron-Frobenius theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small networks Example: Zachary's Karate Club\n",
    "Zachary's Karate Club network is a well-know network example. This is a quite small network so we can compute centralities directly. To better understand the meaning of centrality measure it is useful to visualize them by producing appropriate graph representations.\n",
    "\n",
    "Let's first load and visualize Zachary's Karate Club network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.karate_club_graph()\n",
    "\n",
    "# Fix node positions on all pictures according to spring layout\n",
    "pos = nx.spring_layout(G) \n",
    "nx.draw_networkx(G, pos)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing centralities on graphs\n",
    "We can compute centralities both using NetworkX algorithms and performing iterative procedures. It is important to make sense of the centrality vectors, and a useful way to do this is by visualizing centralities on graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute, for example, the degree centrality of $G$. The following code shows how to represent $G$ so that nodes size and color reflects their centrality value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degree centrality\n",
    "\n",
    "# dc is a dictionary with nodes as keys and degree centralities as values\n",
    "dc = nx.degree_centrality(G) \n",
    "plt.figure(1, figsize=(10,7))\n",
    "# we draw the graph with same node position \"pos\" defined above\n",
    "nx.draw(G,pos,\n",
    "         with_labels=True,\n",
    "         # keys of dc are nodes\n",
    "         nodelist=dc.keys(), \n",
    "         # node size is proportional to centrality value\n",
    "         node_size = [d*10000 for d in dc.values()], \n",
    "         # node's color reflects centrality values (higher dc = darker color)\n",
    "         node_color=list(dc.values()),\n",
    "         font_size=8,\n",
    "         # node's colors are on the red scale\n",
    "         cmap=plt.cm.Reds) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat this procedure with a different measure, eigenvector centrality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigenvector centrality\n",
    "ec = nx.eigenvector_centrality(G)\n",
    "plt.figure(1, figsize=(10,7))\n",
    "nx.draw(G, pos,\n",
    "          with_labels=True,\n",
    "          nodelist=ec.keys(),\n",
    "          # node size is proportional to eigenvector centrality\n",
    "          node_size = [d*10000 for d in ec.values()],  \n",
    "          node_color=list(ec.values()),\n",
    "          font_size=8,\n",
    "          cmap=plt.cm.Reds,\n",
    "          )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to compare different centrality measures for the same graph and see how they are correlated. Below we visualize the correlation between degree centrality and eigenvector centrality of $G$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation degree-eigenvector\n",
    "\n",
    "# x corresponds to degree centrality values\n",
    "xdata = list(dc.values()) \n",
    "# y corresponds to eigenvector centrality values\n",
    "ydata = list(ec.values()) \n",
    "\n",
    "plt.figure(1, figsize=(7,7))\n",
    "# for each node, we plot an \"+\" with coordinates equal to the values of its\n",
    "# degree and eigenvector centrality\n",
    "plt.plot(xdata,ydata, '+') \n",
    "plt.xlabel('Degree Centrality')\n",
    "plt.ylabel('Eigenvector Centrality')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two centralities appear to be correlated for this network. To explore this in more details it is useful to add node ids, so that we can see which are the nodes with higher or lower correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding node ids:\n",
    "\n",
    "# We define a figure and we construct two subplots: \n",
    "# on the left we plot the centralities correlation diagram\n",
    "# with node labels, on the right we draw the graph \n",
    "# with same node labels\n",
    "fig = plt.figure(1, figsize=(14,7))\n",
    "# add_subplot() returns the axes of the subplot\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "for v in range(len(G)):\n",
    "    # Axes.text(x,y,s) add the text s to Axes instance (i.e., to the subplot)\n",
    "    # at location x, y. For each node v we plot \n",
    "    # node ids in position (xdata[v], ydata[v]) where xdata = list(dc.values())\n",
    "    # and ydata = list(ec.values())\n",
    "    ax1.text(x = xdata[v], y = ydata[v], s=str(v))\n",
    "# we set the limits for x and y scales\n",
    "\n",
    "ax1.set_xlim(0, 0.6)\n",
    "ax1.set_ylim(0, 0.4)\n",
    "ax1.set_xlabel('Degree Centrality')\n",
    "ax1.set_ylabel('Eigenvector Centrality')\n",
    "\n",
    "nx.draw_networkx(G, pos, ax=ax2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that node 11 has degree 1, while node 16 has degree 2, so $dc(16)>dc(11)$.\n",
    "\n",
    "However, node 11 is connected to node 0, which has a large value of eigenvector centrality, while node 16 is connected to nodes 5 and 6, which have smaller values of centrality. For this reason, $ec(16)<ec(11)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Invariant distribution centrality**: it generalizes the eigenvector centrality by taking into account that being connected to nodes that connect to many nodes is less important than being connected to nodes that connect with a few nodes.\n",
    "\n",
    "$$\n",
    "z = P'z\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Katz centrality**: it generalizes the eigenvector centrality by assuming that nodes have also an intrinsic centrality. The centrality is the sum of the intrinsic centrality and the centrality given by the network.\n",
    "\n",
    "$$\n",
    "z =  \\frac{1-\\beta}{\\lambda_W} W' z + \\beta \\mu\\,, \\quad \\beta \\in [0,1].\n",
    "$$\n",
    "\n",
    "If $\\beta = 0$, the Katz centrality coincides with the eigenvector centrality. If $\\beta = 1$, then $z=\\mu$.\n",
    "\n",
    "**Bonacich centrality (or Page-rank)**: it generalizes the invariant distribution centrality by assuming that nodes have also an intrinsic centrality. The centrality is the sum of the intrinsic centrality and the centrality given by the network.\n",
    "$$ \n",
    "z = (1-\\beta)P' z + \\beta \\mu\\,, \\quad \\beta \\in [0,1].\n",
    "$$\n",
    "\n",
    "If $\\beta = 0$, it is the invariant distribution centrality. If $\\beta = 1$, then $z=\\mu$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to compute Katz and Bonacich centralities: **direct** and **iterative**.\n",
    "We start by computing those centralities by direct methods for the Zachary's karate club graph.\n",
    "\n",
    "## Direct method (for didactic purposes)\n",
    "Direct methods consist in inverting the equation above and computing directly the centrality. Notice that\n",
    "\n",
    "1. the Katz centrality \n",
    "$ z =  (\\mathbf{I}-\\frac{1-\\beta}{\\lambda_W} W')^{-1} \\beta \\mu $\n",
    "\n",
    "2. and Bonacich centrality \n",
    "$ z = (\\mathbf{I}-(1-\\beta)P')^{-1} \\beta \\mu $\n",
    "\n",
    "Note that the inversion can be done (if $\\beta > 0$) because the matrices $\\frac{1-\\beta}{\\lambda_W} W'$ and $(1-\\beta)P'$ have spectral radius less than 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute matrices of the graph\n",
    "W = nx.adjacency_matrix(G)\n",
    "W = W.toarray()\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = G.number_of_nodes() \n",
    "beta = 0.15\n",
    "mu = np.ones((N,1))\n",
    "# note that the normalization of mu does not influence z, if we consider normalized centralities\n",
    "\n",
    "# compute the largest eigenvalue of W (which is real because of Perron-Frobenius theorem)\n",
    "w,v = np.linalg.eig(W)\n",
    "w = w.real\n",
    "\n",
    "lambda_max = max(w) \n",
    "zk = np.linalg.inv(np.diag(np.ones(N)) - W.T*(1-beta)/lambda_max) * beta @ mu\n",
    "# normalize the centrality\n",
    "zk = zk/sum(zk)\n",
    "\n",
    "print(zk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonacich (Page-rank) centrality\n",
    "Page-rank centrality is the Bonacich centrality with $\\mu=\\mathbf{1}$ and $\\beta=0.15$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zb = np.linalg.inv(np.diag(np.ones(N)) - P.T*(1-beta)) * beta @ mu\n",
    "zb = zb/sum(zb)\n",
    "\n",
    "# transform centralities to float\n",
    "val = [];\n",
    "for i in zb:\n",
    "    val.append(float(i))\n",
    "\n",
    "zb_list = val\n",
    "\n",
    "# sometimes it is useful to store the centralities in a dictionary\n",
    "# create a dictionary to collect the centralities, with nodes as keys and their centrality as values\n",
    "zip_iterator = zip(G.nodes(), zb_list)\n",
    "zb_dict = dict(zip_iterator)\n",
    "\n",
    "print(zb_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute centralities by networkX functions\n",
    "The function `algorithms.link_analysis.pagerank_alg.pagerank` computes the Page-rank centrality of a given network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zb2_dict = nx.algorithms.link_analysis.pagerank_alg.pagerank(G)\n",
    "\n",
    "# check if the centrality are normalized\n",
    "zb2 = np.array(list(zb2_dict.values()))\n",
    "print(\"Normalization:\", sum(zb2), \"\\n\")\n",
    "\n",
    "# transform values to float\n",
    "zb2_list = [];\n",
    "for i in zb2:\n",
    "    zb2_list.append(float(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the Page-rank centrality computed by the inversion formula with the one computed by NetworkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for comparison, it is convenient to use centralities as arrays\n",
    "# before comparing we ensure that the shape of the arrays is the same\n",
    "\n",
    "print(\"Shape of zb:\", zb.shape)\n",
    "print(\"Shape of zb2\", zb2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since it is not, we reshape zb\n",
    "zb = zb.reshape(N)\n",
    "\n",
    "# now we can compute the distance\n",
    "print(\"Distance between zb and zb2:\", np.linalg.norm(zb-zb2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative methods\n",
    "The smartest way to compute Bonacich centrality (or Katz centrality) is by iterative methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the dynamics\n",
    "$$\n",
    "\\begin{cases} \n",
    "z(t+1) = (1-\\beta)P'z(t) + \\beta \\mu  \\\\\n",
    "z(0) = z_0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The transient of the dynamics is\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "z(1) = (1-\\beta)P'z(0) + \\beta \\mu\\\\\n",
    "z(2) = (1-\\beta)^2 (P')^2 z(0) + (1-\\beta)P' \\beta \\mu + \\beta \\mu\\\\\n",
    "\\vdots\\\\\n",
    "z(t) = (1-\\beta)^t (P')^t z(0) + \\sum_{i=0}^{t-1} (1-\\beta)^i (P')^i \\beta \\mu\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The first term vanishes as $t \\to +\\infty$ because $(1-\\beta)P'$ is sub-stochastic, while the second term is a geometric sum. The dynamics thus converges to the limit\n",
    "\n",
    "$$\n",
    "\\lim_{t \\to +\\infty} z(t) = (\\mathbf{I}-(1-\\beta) P')^{-1} \\beta \\mu,\n",
    "$$\n",
    "\n",
    "which is the Bonacich centrality of the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark 1**: You should never use direct ways to compute centralities if iterative algorithms are available. The iterative method is more efficient than the direct one as the order of the graph grows, since it does not involve the inversion of a $N \\times N$ matrix.\n",
    "\n",
    "**Remark 2**: Note that the convergence of $z(t)$ to the Bonacich centrality holds for every initial condition $z_0$ and the limit is independent of $z_0$.\n",
    "\n",
    "**Remark 3**: Notice that the proposed method is **distributed**, i.e., the operations at single node levels do not require a complete knowledge of the network. Each node $i$ updates its state $z_i(t+1)$ by using only local information, i.e., the i-th row of $W$ and the state $z_j(t)$ of nodes $j$ that are adjacent to $j$.\n",
    "\n",
    "Let us implement the distributed method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = G.number_of_nodes()\n",
    "beta = 0.15\n",
    "mu = np.ones((N,1))/N\n",
    "\n",
    "# arbitrary initial condition: 1/N-uniform vector of size N (initial condition does not matters)\n",
    "z_0 = np.ones((N,1))/N\n",
    "\n",
    "# set a tolerance to assess convergence to the limit\n",
    "tol = 1e-5\n",
    "\n",
    "# run the dynamics\n",
    "z_old = z_0\n",
    "\n",
    "while True:\n",
    "    z_new = P.T @ z_old * (1-beta) + beta * mu\n",
    "    if np.linalg.norm(z_new-z_old) < tol:\n",
    "        break\n",
    "    z_old=z_new\n",
    "\n",
    "zb_distr = z_new\n",
    "\n",
    "# normalize the centrality\n",
    "zb_distr = zb_distr / sum(zb_distr)\n",
    "\n",
    "print(\"Bonacich centrality: \\n\", zb_distr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Katz centrality\n",
    "\n",
    "For Katz centrality, consider the following dynamics:\n",
    "\n",
    "$$\n",
    "\\begin{cases} \n",
    "z(t+1) = \\frac{(1-\\beta)}{\\lambda_W}W'z(t) + \\beta \\mu  \\\\\n",
    "z(0) = z_0.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "It is easy to prove that the dynamics converges to the Katz centrality.\n",
    "\n",
    "**Remark**: notice that the proposed method is iterative (and therefore more efficient than direct method), but it is not distributed. Indeed, to perform the computation, every node needs to know $\\lambda_W$, which is a global information on the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Compute the Katz centrality of the Zachary's karate club graph by iterative methods, and compare the results with direct methods.\n",
    "\n",
    "**Hint**: use the definition of Katz centrality and same techniques as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing sensitivity of measures\n",
    "In this section we will check the dependence of centrality measures with respect to their paramenters and the sensitivity of the iterative algorithms to compute such measure with respect to the number of iterations.\n",
    "\n",
    "## The effect of parameters\n",
    "In our first experiment we analyze the dependence of Page Rank centrality on the parameter $\\alpha=1-\\beta$. We set distinct values for $\\alpha$ while we fix the number of iterations, and run Page Rank. Then we plot the resulting Page Rank values with respect to $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(2, figsize=(16,7))\n",
    "ax1 = plt.subplot(121)\n",
    "ax2 = plt.subplot(122)\n",
    "\n",
    "pos = nx.spring_layout(G) \n",
    "nx.draw_networkx(G, pos, ax=ax1)\n",
    "\n",
    "# we consider values for alpha from 0 to 1 with step size 0.25\n",
    "alphas = np.arange(0, 1.25, 0.25)\n",
    "\n",
    "for alp in alphas:\n",
    "    # pagerank has parameters alpha and mu:\n",
    "    # note that alpha = 1-beta and weight parameters mu are set to 1 by default\n",
    "    pr = nx.pagerank(G, alpha=alp) \n",
    "    prval = list(pr.values())\n",
    "    ax2.plot(prval, color=np.random.rand(3), label='alpha {0:.2f}'.format(alp))\n",
    "    \n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explain the previous result. Keep in mind that the parameter alpha used by `nx.pagerank` corresponds to $1-\\beta$, and the centrality $z$ satisfies\n",
    "\n",
    "$$\n",
    "z = (1-\\beta)P'z + \\beta \\mu\n",
    "$$\n",
    "\n",
    "- As $\\alpha = 0$ ($\\beta = 1$), $z = \\mu$, i.e., Bonacich is equivalent to the intrinsic centrality $\\mu$, the network does not play any role.\n",
    "\n",
    "- As $\\alpha = 1$ ($\\beta = 0$), $z = P'z$, i.e., Bonacich is equivalent to invariant distribution centrality (the intrinsic centrality is irrelevant).\n",
    "\n",
    "In between these two extreme cases there is a combination of network effects and intrinsic centrality.\n",
    "\n",
    "## Exercise\n",
    "Repeat the analysis. This time keep $\\alpha$ fixed to 0.5 and select 3 different non-uniform vectors $\\mu$ as `personalization` parameter to `pagerank`. How do you interpret the result?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The effect of iteration number\n",
    "In this section we consider a bigger network and we analyse the speed of convergence of iterative algorithms for computing centrality measures. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_gml('polblogs.gml')\n",
    "print(\"Type of G:\", type(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $G$ is a multidigraph, we define an equivalent digraph to compute the centralities (the function 'pagerank' does not work with multigraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GG = nx.DiGraph()\n",
    "for n, nbrs in G.adjacency():\n",
    "    # edict is a dictionary of dictionaries; \n",
    "    # the keys of edict are parallel edges from n to nbr;\n",
    "    # the values of edict are dictionary,\n",
    "    # containing attribute values of the corresponding edge\n",
    "    for nbr, edict in nbrs.items(): \n",
    "        # each edge has weight=1, so total value is just  \n",
    "        # the number of parallel edges\n",
    "        total_value = len(edict) \n",
    "        GG.add_edge(n, nbr, weight = total_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph is very large, thus we cannot plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(GG.number_of_nodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now test the convergence speed of `nx.pagerank` algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(16,7))\n",
    "\n",
    "# set 3 iteration numbers\n",
    "iters = [10,15,50]\n",
    "# define the position of the next plot in the subplot grid\n",
    "position = 1\n",
    "# create a list to collect the page rank values obtained in the three runs \n",
    "prvals = []\n",
    "\n",
    "for max_iter in iters:\n",
    "    # compute page rank\n",
    "    pr = nx.pagerank(GG, max_iter = max_iter) \n",
    "    # compute page rank values\n",
    "    prval = list(pr.values())\n",
    "    # append the result to the list\n",
    "    prvals.append(np.array(prval)) \n",
    "    # create a new sublot in the grid\n",
    "    ax = fig.add_subplot(2,2,position)\n",
    "    # plot the PR values\n",
    "    ax.plot(prval, color=np.random.rand(3), label='{0:d} iterations'.format(max_iter))\n",
    "    position+=1\n",
    "\n",
    "# add a legend which contains all labels\n",
    "# informations specified in previous plot calls\n",
    "fig.legend()  \n",
    "# we assume the values obtained with nx.pagerank()\n",
    "# with no iterations constraints as a benchmark\n",
    "benchmark = np.array(list(nx.pagerank(GG).values())) \n",
    "# we compute errors as norm of the differences wrt the benchmark\n",
    "errors = [np.linalg.norm(prval-benchmark) for prval in prvals]\n",
    "print(\"Errors:\", errors)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nx.pagerank` algorithm converges very fast, in 10 iterations! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Check if our iterative algorithm for computing Bonacich centrality is as good as this by performing a similar analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An interpretation of Katz (and Bonacich) centrality\n",
    "Bonacich centrality (as well as Katz centrality) can be interpreted in terms of walks on the graphs.\n",
    "We show this by an example.\n",
    "\n",
    "We shall make use of an undirected graph and Katz centrality to simplify the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.lollipop_graph(6,3)\n",
    "G.add_edges_from([(9,8),(10,8),(11,8),(12,8),(13,8)])\n",
    "\n",
    "pos = nx.spring_layout(G) \n",
    "nx.draw(G, pos, with_labels = True)\n",
    "\n",
    "N = len(G)\n",
    "\n",
    "# compute matrices of the graph\n",
    "W = nx.adjacency_matrix(G)\n",
    "W = W.toarray()\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "# compute the largest eigenvalue of W\n",
    "w,v = np.linalg.eig(W)\n",
    "w = w.real\n",
    "\n",
    "lambda_max = max(w) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the iterative implementation of Katz centrality\n",
    "$$\n",
    "\\begin{cases} \n",
    "z(t+1) = \\frac{(1-\\beta)}{\\lambda_W}W'z(t) + \\beta \\mu  \\\\\n",
    "z(0) = z_0.\n",
    "\\end{cases}\n",
    "$$\n",
    "with uniform $z_0$ and $\\mu$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.ones((N,1))/N\n",
    "beta = 0.15\n",
    "# initial centrality distribution\n",
    "z = np.ones((N,1))/N\n",
    "z_reshape = z.reshape(N)\n",
    "\n",
    "print(\"Centralities at iteration 0:\", z_reshape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that normalizing $\\mu$ does not modify the centrality, since in\n",
    "\n",
    "$$ \n",
    "z =  (\\mathbf{I}-\\frac{1-\\beta}{\\lambda_W} W')^{-1} \\beta \\mu \n",
    "$$\n",
    "\n",
    "$\\mu$ affects the normalization of $z$ only (same for Bonacich centrality). \n",
    "\n",
    "However, the normalization of $\\mu$ affects the transient of the iteration to compute $z$. In particular, if one considers the **Bonacich centrality**, using $\\mu, z_0$ such that $\\mathbf{1}' \\mu = \\mathbf{1}' z_0 = \\mathbf{1}$ is preferable, since it guarantees that, if $\\mathbf{1}' z(0)=1$, then $\\mathbf{1}' z(t)=1$ for every $t$. Indeed, if $\\mathbf{1}' z(t-1)= 1$, then \n",
    "\n",
    "$$\n",
    "\\mathbf{1}' z(t) = (1-\\beta) \\mathbf{1}' P' z(t-1) + \\beta \\mathbf{1}'\\mu = (1-\\beta) \\mathbf{1}' z(t-1) + \\beta = (1-\\beta) + \\beta = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to Katz centrality\n",
    "\n",
    "After 1 iteration,\n",
    "$$\n",
    "z(1) = \\frac{(1-\\beta)}{\\lambda_W}W'z(0) + \\beta \\mu,\n",
    "$$\n",
    "\n",
    "which means that the centrality of a node is the a combination of its intrinsic centrality, and the centrality of the neighbors. Since the intrinsic centrality is the same for every node, if we start with a uniform $z(0)$, $z(1)$ depends only on the degree of the node.\n",
    "\n",
    "Similar observation can be made for the Bonacich centrality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after 1 iteration\n",
    "z = W.T @ z * (1-beta)/lambda_max + beta * mu\n",
    "\n",
    "z_reshape = z.reshape(N)\n",
    "\n",
    "nodesize=z_reshape*7000\n",
    "\n",
    "# plot centrality at iteration 0\n",
    "plt.figure(1, figsize=(10,7))\n",
    "# we draw the graph with same node position \"pos\" defined above\n",
    "nx.draw(G,pos,\n",
    "         with_labels=True,\n",
    "         nodelist=list(G.nodes()), \n",
    "         # node size is proportional to centrality value\n",
    "         node_size = nodesize, \n",
    "         # node's color reflects centrality values (higher dc = darker color)\n",
    "         node_color=z_reshape,\n",
    "         font_size=8,\n",
    "         # node's colors are on the red scale\n",
    "         cmap=plt.cm.Reds) \n",
    "\n",
    "print(\"Centralities at iteration 1:\", z_reshape)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the number of iterations grows, $z(n)$ takes into account also nodes at greater distance.\n",
    "\n",
    "At the equilibrium, the centrality $z^*$ can be interpreted in terms of walks as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "z^*&=\\lim_{n \\to +\\infty}z(n)=\\sum_{n = 0}^{\\infty} \\left(\\frac{(1-\\beta)}{\\lambda_W}\\right)^n (W')^n \\beta \\mu \\\\\n",
    "   &= \\beta \\mu + \\frac{(1-\\beta)}{\\lambda_W} (W') \\beta \\mu + \\left(\\frac{(1-\\beta)}{\\lambda_W}\\right)^2 (W')^2 \\beta \\mu + \\cdots\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "If one considers node $i$\n",
    "\n",
    "$$\n",
    "z^*_i = \\beta \\mu_i + \\frac{(1-\\beta)}{\\lambda_W}\\beta \\sum_{j} (W')_{ij} \\mu_j + \\left(\\frac{(1-\\beta)}{\\lambda_W}\\right)^2 \\beta \\sum_{j} ((W')^2)_{ij} \\mu_j + \\cdots\n",
    "$$\n",
    "\n",
    "**Interpretation**. Since $((W')^n)_{ij}$ is the number of paths of length $n$ from $j$ to $i$, the centrality of node $i$ is the sum of:\n",
    "- its intrinsic centrality $\\mu_i$, plus \n",
    "- the intrinsic centrality of its in-neighbors, i.e., $\\sum_j W_{ji} \\mu_j$, plus \n",
    "- the intrinsic centrality of the nodes connected by paths of length 2, and so on... \n",
    "\n",
    "Longer paths have a decreasing weight due to the term $(1-\\beta)^n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: which node do you expect to have a higher Katz centrality? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a tolerance to assess convergence to the limit\n",
    "tol = 1e-5\n",
    "\n",
    "z_0 = np.ones(N,)/N\n",
    "mu = np.ones(N,)/N\n",
    "\n",
    "# run the dynamics\n",
    "z_old = z_0\n",
    "print()\n",
    "while True:\n",
    "    z_new = W.T @ z_old * (1-beta)/lambda_max + beta * mu\n",
    "    if np.linalg.norm(z_new-z_old) < tol:\n",
    "        break\n",
    "    z_old=z_new\n",
    "\n",
    "zk = z_new\n",
    "\n",
    "# normalize the centrality\n",
    "zk = zk/sum(zk)\n",
    "zk = zk.reshape(N)\n",
    "\n",
    "print(zk)\n",
    "\n",
    "plt.figure(1, figsize=(10,7))\n",
    "# we draw the graph with same node position \"pos\" defined above\n",
    "nx.draw(G,pos,\n",
    "         with_labels=True,\n",
    "         nodelist=list(G.nodes()), \n",
    "         # node size is proportional to centrality value\n",
    "         node_size = zk*7000, \n",
    "         # node's color reflects centrality values (higher dc = darker color)\n",
    "         node_color=zk,\n",
    "         font_size=8,\n",
    "         # node's colors are on the red scale\n",
    "         cmap=plt.cm.Reds) \n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: how do you expect to be modified the centralities when using Bonacich instead of Katz? Focus on node 8 vs node 5.\n",
    "\n",
    "**Hint**: recall the definition of the two centralities, i.e.,\n",
    "\n",
    "- Katz: $z =  \\frac{1-\\beta}{\\lambda_W} W' z + \\beta \\mu$\n",
    "- Bonacich: $x = (1-\\beta)P' x + \\beta \\mu$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zb_dict = nx.algorithms.link_analysis.pagerank_alg.pagerank(G)\n",
    "\n",
    "# check if the centrality are normalized\n",
    "zb = np.array(list(zb_dict.values()))\n",
    "\n",
    "print(zk)\n",
    "\n",
    "plt.figure(1, figsize=(10,7))\n",
    "# we draw the graph with same node position \"pos\" defined above\n",
    "nx.draw(G,pos,\n",
    "         with_labels=True,\n",
    "         nodelist=list(G.nodes()), \n",
    "         # node size is proportional to centrality value\n",
    "         node_size = zb*7000, \n",
    "         # node's color reflects centrality values (higher dc = darker color)\n",
    "         node_color=zb,\n",
    "         font_size=8,\n",
    "         # node's colors are on the red scale\n",
    "         cmap=plt.cm.Reds) \n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Compute all the centralities for the this graph, plot them, and comment the results.\n",
    "\n",
    "**Hint**: use the code introduced in the lectures to compute the degree, eigenvector, Katz and Bonacich centralities. For the invariant distribution centrality use the function `np.linalg.eig()` to find the invariant distribution of $P$. Use the code introduced in the last lecture to plot the centralities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_components = tuple(nx.algorithms.components.attracting_components(G))\n",
    "\n",
    "for c in attr_components:\n",
    "    # construct the induced subgraph with nodes from the attractive component c\n",
    "    sG = G.subgraph(c)\n",
    "    # construct the matrix P on the subgraph\n",
    "    W = nx.adjacency_matrix(sG)\n",
    "    W = W.toarray()\n",
    "    degrees = np.sum(W,axis=1)\n",
    "    D = np.diag(degrees)\n",
    "    P = np.linalg.inv(D) @ W\n",
    "    # find the extremal dominant eigenvector corresponding to component c\n",
    "    w,v = np.linalg.eig(P.T)\n",
    "    for index in [i for i in range(len(sG)) if np.isclose(w[i],1)]: \n",
    "        pi = v[:,index].real  # -> eigenvectors are complex but pi is real, so we convert it to real\n",
    "        pi = pi/np.sum(pi)\n",
    "    # map pi back in the original node space\n",
    "    pi_G = np.zeros(len(G))\n",
    "    for i in range(len(sG)):\n",
    "        pi_G[list(sG.nodes)[i]-1] = pi[i] # shift by -1 because nodes are (1,...10) while vector indexes are (0,...,9)\n",
    "    print(\"pi:\", pi_G, \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
