{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network centralities\n",
    "\n",
    "**Katz centrality**: it generalizes the eigenvector centrality by assuming that nodes have also an intrinsic centrality. The centrality is the sum of the intrinsic centrality and the centrality given by the network.\n",
    "\n",
    "$$\n",
    "z =  \\frac{1-\\beta}{\\lambda_W} W' z + \\beta \\mu\\,, \\quad \\beta \\in [0,1].\n",
    "$$\n",
    "\n",
    "If $\\beta = 0$, the Katz centrality coincides with the eigenvector centrality. If $\\beta = 1$, then $z=\\mu$.\n",
    "\n",
    "**Bonacich centrality (or Page-rank)**: it generalizes the invariant distribution centrality by assuming that nodes have also an intrinsic centrality. The centrality is the sum of the intrinsic centrality and the centrality given by the network.\n",
    "$$ \n",
    "z = (1-\\beta)P' z + \\beta \\mu\\,, \\quad \\beta \\in [0,1].\n",
    "$$\n",
    "\n",
    "If $\\beta = 0$, it is the invariant distribution centrality. If $\\beta = 1$, then $z=\\mu$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative methods to compute network centralities\n",
    "The smartest way to compute Bonacich centrality (or Katz centrality) is by iterative methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the dynamics\n",
    "$$\n",
    "\\begin{cases} \n",
    "z(t+1) = (1-\\beta)P'z(t) + \\beta \\mu  \\\\\n",
    "z(0) = z_0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The transient of the dynamics is\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "z(1) = (1-\\beta)P'z(0) + \\beta \\mu\\\\\n",
    "z(2) = (1-\\beta)^2 (P')^2 z(0) + (1-\\beta)P' \\beta \\mu + \\beta \\mu\\\\\n",
    "\\vdots\\\\\n",
    "z(t) = (1-\\beta)^t (P')^t z(0) + \\sum_{i=0}^{t-1} (1-\\beta)^i (P')^i \\beta \\mu\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The first term vanishes as $t \\to +\\infty$ because $(1-\\beta)P'$ is sub-stochastic, while the second term is a geometric sum. The dynamics thus converges to the limit\n",
    "\n",
    "$$\n",
    "\\lim_{t \\to +\\infty} z(t) = (\\mathbf{I}-(1-\\beta) P')^{-1} \\beta \\mu,\n",
    "$$\n",
    "\n",
    "which is the Bonacich centrality of the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark 1**: You should never use direct ways to compute centralities if iterative algorithms are available. The iterative method is more efficient than the direct one as the order of the graph grows, since it does not involve the inversion of a $N \\times N$ matrix.\n",
    "\n",
    "**Remark 2**: Note that the convergence of $z(t)$ to the Bonacich centrality holds for every initial condition $z_0$ and the limit is independent of $z_0$.\n",
    "\n",
    "**Remark 3**: Notice that the proposed method is **distributed**, i.e., the operations at single node levels do not require a complete knowledge of the network. Each node $i$ updates its state $z_i(t+1)$ by using only local information, i.e., the i-th row of $W$ and the state $z_j(t)$ of nodes $j$ that are adjacent to $j$.\n",
    "\n",
    "Let us implement the distributed method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "G = nx.karate_club_graph()\n",
    "\n",
    "# Fix node positions on all pictures according to spring layout\n",
    "pos = nx.spring_layout(G) \n",
    "nx.draw_networkx(G, pos)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# compute matrices of the graph\n",
    "W = nx.adjacency_matrix(G)\n",
    "W = W.toarray()\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "N = G.number_of_nodes()\n",
    "beta = 0.15\n",
    "mu = np.ones((N,1))/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arbitrary initial condition: 1/N-uniform vector of size N (initial condition does not matters)\n",
    "z_0 = np.ones((N,1))/N\n",
    "\n",
    "# set a tolerance to assess convergence to the limit\n",
    "tol = 1e-5\n",
    "\n",
    "# run the dynamics\n",
    "z_old = z_0\n",
    "\n",
    "while True:\n",
    "    z_new = P.T @ z_old * (1-beta) + beta * mu\n",
    "    if np.linalg.norm(z_new-z_old) < tol:\n",
    "        break\n",
    "    z_old=z_new\n",
    "\n",
    "zb_distr = z_new\n",
    "\n",
    "# normalize the centrality\n",
    "zb_distr = zb_distr / sum(zb_distr)\n",
    "\n",
    "print(\"Bonacich centrality: \\n\", zb_distr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Katz centrality\n",
    "\n",
    "For Katz centrality, consider the following dynamics:\n",
    "\n",
    "$$\n",
    "\\begin{cases} \n",
    "z(t+1) = \\frac{(1-\\beta)}{\\lambda_W}W'z(t) + \\beta \\mu  \\\\\n",
    "z(0) = z_0.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "It is easy to prove that the dynamics converges to the Katz centrality.\n",
    "\n",
    "**Remark**: notice that the proposed method is iterative (and therefore more efficient than direct method), but it is not distributed. Indeed, to perform the computation, every node needs to know $\\lambda_W$, which is a global information on the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Compute the Katz centrality of the Zachary's karate club graph by iterative methods, and compare the results with direct methods.\n",
    "\n",
    "**Hint**: use the definition of Katz centrality and same techniques as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing sensitivity of measures\n",
    "In this section we will check the dependence of centrality measures with respect to their paramenters and the sensitivity of the iterative algorithms to compute such measure with respect to the number of iterations.\n",
    "\n",
    "## The effect of parameters\n",
    "In our first experiment we analyze the dependence of Page Rank centrality on the parameter $\\alpha=1-\\beta$. We set distinct values for $\\alpha$ while we fix the number of iterations, and run Page Rank. Then we plot the resulting Page Rank values with respect to $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(2, figsize=(16,7))\n",
    "ax1 = plt.subplot(121)\n",
    "ax2 = plt.subplot(122)\n",
    "\n",
    "pos = nx.spring_layout(G) \n",
    "nx.draw_networkx(G, pos, ax=ax1)\n",
    "\n",
    "# we consider values for alpha from 0 to 1 with step size 0.25\n",
    "alphas = np.arange(0, 1.25, 0.25)\n",
    "\n",
    "for alp in alphas:\n",
    "    # pagerank has parameters alpha and mu:\n",
    "    # note that alpha = 1-beta and weight parameters mu are set to 1 by default\n",
    "    pr = nx.pagerank(G, alpha=alp) \n",
    "    prval = list(pr.values())\n",
    "    ax2.plot(prval, color=np.random.rand(3), label='alpha {0:.2f}'.format(alp))\n",
    "    \n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explain the previous result. Keep in mind that the parameter alpha used by `nx.pagerank` corresponds to $1-\\beta$, and the centrality $z$ satisfies\n",
    "\n",
    "$$\n",
    "z = (1-\\beta)P'z + \\beta \\mu\n",
    "$$\n",
    "\n",
    "- As $\\alpha = 0$ ($\\beta = 1$), $z = \\mu$, i.e., Bonacich is equivalent to the intrinsic centrality $\\mu$, the network does not play any role.\n",
    "\n",
    "- As $\\alpha = 1$ ($\\beta = 0$), $z = P'z$, i.e., Bonacich is equivalent to invariant distribution centrality (the intrinsic centrality is irrelevant).\n",
    "\n",
    "In between these two extreme cases there is a combination of network effects and intrinsic centrality.\n",
    "\n",
    "## Exercise ##\n",
    "Repeat the analysis. This time keep $\\alpha$ fixed to 0.5 and select 3 different non-uniform vectors $\\mu$ as `personalization` parameter to `pagerank`. How do you interpret the result?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The effect of iteration number\n",
    "In this section we consider a bigger network and we analyse the speed of convergence of iterative algorithms for computing centrality measures. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the political blogs network (save it as a .gml file in the working directory of this notebook) and import it as a Graph object. We check the basic properties of $G$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_gml('polblogs.gml')\n",
    "print(\"Type of G:\", type(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $G$ is a multidigraph, we define an equivalent digraph to compute the centralities (the function 'pagerank' does not work with multigraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GG = nx.DiGraph()\n",
    "for n, nbrs in G.adjacency():\n",
    "    # edict is a dictionary of dictionaries; \n",
    "    # the keys of edict are parallel edges from n to nbr;\n",
    "    # the values of edict are dictionary,\n",
    "    # containing attribute values of the corresponding edge\n",
    "    for nbr, edict in nbrs.items(): \n",
    "        # each edge has weight=1, so total value is just  \n",
    "        # the number of parallel edges\n",
    "        total_value = len(edict) \n",
    "        GG.add_edge(n, nbr, weight = total_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph is very large, thus we cannot plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(GG.number_of_nodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now test the convergence speed of `nx.pagerank` algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(16,7))\n",
    "\n",
    "# set 3 iteration numbers\n",
    "iters = [10,15,50]\n",
    "# define the position of the next plot in the subplot grid\n",
    "position = 1\n",
    "# create a list to collect the page rank values obtained in the three runs \n",
    "prvals = []\n",
    "\n",
    "for max_iter in iters:\n",
    "    # compute page rank\n",
    "    pr = nx.pagerank(GG, max_iter = max_iter) \n",
    "    # compute page rank values\n",
    "    prval = list(pr.values())\n",
    "    # append the result to the list\n",
    "    prvals.append(np.array(prval)) \n",
    "    # create a new sublot in the grid\n",
    "    ax = fig.add_subplot(2,2,position)\n",
    "    # plot the PR values\n",
    "    ax.plot(prval, color=np.random.rand(3), label='{0:d} iterations'.format(max_iter))\n",
    "    position+=1\n",
    "\n",
    "# add a legend which contains all labels\n",
    "# informations specified in previous plot calls\n",
    "fig.legend()  \n",
    "# we assume the values obtained with nx.pagerank()\n",
    "# with no iterations constraints as a benchmark\n",
    "benchmark = np.array(list(nx.pagerank(GG).values())) \n",
    "# we compute errors as norm of the differences wrt the benchmark\n",
    "errors = [np.linalg.norm(prval-benchmark) for prval in prvals]\n",
    "print(\"Errors:\", errors)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nx.pagerank` algorithm converges very fast, in 10 iterations! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Check if our iterative algorithm for computing Bonacich centrality is as good as this by performing a similar analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An interpretation of Katz (and Bonacich) centrality\n",
    "Bonacich centrality (as well as Katz centrality) can be interpreted in terms of walks on the graphs.\n",
    "We show this by an example.\n",
    "\n",
    "We shall make use of an undirected graph and Katz centrality to simplify the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.lollipop_graph(6,3)\n",
    "G.add_edges_from([(9,8),(10,8),(11,8),(12,8),(13,8)])\n",
    "\n",
    "pos = nx.spring_layout(G) \n",
    "nx.draw(G, pos, with_labels = True)\n",
    "\n",
    "N = len(G)\n",
    "\n",
    "# compute matrices of the graph\n",
    "W = nx.adjacency_matrix(G)\n",
    "W = W.toarray()\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "# compute the largest eigenvalue of W\n",
    "w,v = np.linalg.eig(W)\n",
    "w = w.real\n",
    "\n",
    "lambda_max = max(w) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the iterative implementation of Katz centrality\n",
    "$$\n",
    "\\begin{cases} \n",
    "z(t+1) = \\frac{(1-\\beta)}{\\lambda_W}W'z(t) + \\beta \\mu  \\\\\n",
    "z(0) = z_0.\n",
    "\\end{cases}\n",
    "$$\n",
    "with uniform $z_0$ and $\\mu$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.ones((N,1))/N\n",
    "beta = 0.15\n",
    "# initial centrality distribution\n",
    "z = np.ones((N,1))/N\n",
    "z_reshape = z.reshape(N)\n",
    "\n",
    "print(\"Centralities at iteration 0:\", z_reshape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that normalizing $\\mu$ does not modify the centrality, since in\n",
    "\n",
    "$$ \n",
    "z =  (\\mathbf{I}-\\frac{1-\\beta}{\\lambda_W} W')^{-1} \\beta \\mu \n",
    "$$\n",
    "\n",
    "$\\mu$ affects the normalization of $z$ only (same for Bonacich centrality). \n",
    "\n",
    "However, the normalization of $\\mu$ affects the transient of the iteration to compute $z$. In particular, if one considers the **Bonacich centrality**, using $\\mu, z_0$ such that $\\mathbf{1}' \\mu = \\mathbf{1}' z_0 = \\mathbf{1}$ is preferable, since it guarantees that, if $\\mathbf{1}' z(0)=1$, then $\\mathbf{1}' z(t)=1$ for every $t$. Indeed, if $\\mathbf{1}' z(t-1)= 1$, then \n",
    "\n",
    "$$\n",
    "\\mathbf{1}' z(t) = (1-\\beta) \\mathbf{1}' P' z(t-1) + \\beta \\mathbf{1}'\\mu = (1-\\beta) \\mathbf{1}' z(t-1) + \\beta = (1-\\beta) + \\beta = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to Katz centrality\n",
    "\n",
    "After 1 iteration,\n",
    "$$\n",
    "z(1) = \\frac{(1-\\beta)}{\\lambda_W}W'z(0) + \\beta \\mu,\n",
    "$$\n",
    "\n",
    "which means that the centrality of a node is the a combination of its intrinsic centrality, and the centrality of the neighbors. Since the intrinsic centrality is the same for every node, if we start with a uniform $z(0)$, $z(1)$ depends only on the degree of the node.\n",
    "\n",
    "Similar observation can be made for the Bonacich centrality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after 1 iteration\n",
    "z = W.T @ z * (1-beta)/lambda_max + beta * mu\n",
    "\n",
    "z_reshape = z.reshape(N)\n",
    "\n",
    "nodesize=z_reshape*7000\n",
    "\n",
    "# plot centrality at iteration 0\n",
    "plt.figure(1, figsize=(10,7))\n",
    "# we draw the graph with same node position \"pos\" defined above\n",
    "nx.draw(G,pos,\n",
    "         with_labels=True,\n",
    "         nodelist=list(G.nodes()), \n",
    "         # node size is proportional to centrality value\n",
    "         node_size = nodesize, \n",
    "         # node's color reflects centrality values (higher dc = darker color)\n",
    "         node_color=z_reshape,\n",
    "         font_size=8,\n",
    "         # node's colors are on the red scale\n",
    "         cmap=plt.cm.Reds) \n",
    "\n",
    "print(\"Centralities at iteration 1:\", z_reshape)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the number of iterations grows, $z(n)$ takes into account also nodes at greater distance.\n",
    "\n",
    "At the equilibrium, the centrality $z^*$ can be interpreted in terms of walks as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "z^*&=\\lim_{n \\to +\\infty}z(n)=\\sum_{n = 0}^{\\infty} \\left(\\frac{(1-\\beta)}{\\lambda_W}\\right)^n (W')^n \\beta \\mu \\\\\n",
    "   &= \\beta \\mu + \\frac{(1-\\beta)}{\\lambda_W} (W') \\beta \\mu + \\left(\\frac{(1-\\beta)}{\\lambda_W}\\right)^2 (W')^2 \\beta \\mu + \\cdots\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "If one considers node $i$\n",
    "\n",
    "$$\n",
    "z^*_i = \\beta \\mu_i + \\frac{(1-\\beta)}{\\lambda_W}\\beta \\sum_{j} (W')_{ij} \\mu_j + \\left(\\frac{(1-\\beta)}{\\lambda_W}\\right)^2 \\beta \\sum_{j} ((W')^2)_{ij} \\mu_j + \\cdots\n",
    "$$\n",
    "\n",
    "**Interpretation**. Since $((W')^n)_{ij}$ is the number of paths of length $n$ from $j$ to $i$, the centrality of node $i$ is the sum of:\n",
    "- its intrinsic centrality $\\mu_i$, plus \n",
    "- the intrinsic centrality of its in-neighbors, i.e., $\\sum_j W_{ji} \\mu_j$, plus \n",
    "- the intrinsic centrality of the nodes connected by paths of length 2, and so on... \n",
    "\n",
    "Longer paths have a decreasing weight due to the term $(1-\\beta)^n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: which node do you expect to have a higher Katz centrality? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a tolerance to assess convergence to the limit\n",
    "tol = 1e-5\n",
    "\n",
    "z_0 = np.ones(N,)/N\n",
    "mu = np.ones(N,)/N\n",
    "\n",
    "# run the dynamics\n",
    "z_old = z_0\n",
    "print()\n",
    "while True:\n",
    "    z_new = W.T @ z_old * (1-beta)/lambda_max + beta * mu\n",
    "    if np.linalg.norm(z_new-z_old) < tol:\n",
    "        break\n",
    "    z_old=z_new\n",
    "\n",
    "zk = z_new\n",
    "\n",
    "# normalize the centrality\n",
    "zk = zk/sum(zk)\n",
    "zk = zk.reshape(N)\n",
    "\n",
    "print(zk)\n",
    "\n",
    "plt.figure(1, figsize=(10,7))\n",
    "# we draw the graph with same node position \"pos\" defined above\n",
    "nx.draw(G,pos,\n",
    "         with_labels=True,\n",
    "         nodelist=list(G.nodes()), \n",
    "         # node size is proportional to centrality value\n",
    "         node_size = zk*7000, \n",
    "         # node's color reflects centrality values (higher dc = darker color)\n",
    "         node_color=zk,\n",
    "         font_size=8,\n",
    "         # node's colors are on the red scale\n",
    "         cmap=plt.cm.Reds) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: how do you expect to be modified the centralities when using Bonacich instead of Katz? Focus on node 8 vs node 5.\n",
    "\n",
    "**Hint**: recall the definition of the two centralities, i.e.,\n",
    "\n",
    "- Katz: $z =  \\frac{1-\\beta}{\\lambda_W} W' z + \\beta \\mu$\n",
    "- Bonacich: $x = (1-\\beta)P' x + \\beta \\mu$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zb_dict = nx.algorithms.link_analysis.pagerank_alg.pagerank(G)\n",
    "\n",
    "# check if the centrality are normalized\n",
    "zb = np.array(list(zb_dict.values()))\n",
    "\n",
    "print(zk)\n",
    "\n",
    "plt.figure(1, figsize=(10,7))\n",
    "# we draw the graph with same node position \"pos\" defined above\n",
    "nx.draw(G,pos,\n",
    "         with_labels=True,\n",
    "         nodelist=list(G.nodes()), \n",
    "         # node size is proportional to centrality value\n",
    "         node_size = zb*7000, \n",
    "         # node's color reflects centrality values (higher dc = darker color)\n",
    "         node_color=zb,\n",
    "         font_size=8,\n",
    "         # node's colors are on the red scale\n",
    "         cmap=plt.cm.Reds) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Compute all the centralities for the this graph, plot them, and comment the results.\n",
    "\n",
    "**Hint**: use the code introduced in the lectures to compute the degree, eigenvector, Katz and Bonacich centralities. For the invariant distribution centrality use the function `np.linalg.eig()` to find the invariant distribution of $P$. Use the code introduced in the last lecture to plot the centralities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flows over networks\n",
    "In this part of the lab we discuss how maximum admissible flows on a capacitated network are related with cuts in the network by the Max Flow - Min Cut theorem. \n",
    "\n",
    "Let us start with the definition of flows from a source 's' to a destination 't' (called terminal nodes).\n",
    "\n",
    "**Definition**: a s-t flow is a distribution such that:\n",
    "- for every non-terminal node the incoming flow equals the outcoming flow (mass conservation);\n",
    "- the outcoming flow from $s$ equals the incoming flow to $t$ (this quantity is called **throughput**).\n",
    "\n",
    "### Example\n",
    "The blue edge labels indicate the flow along the edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "G.add_edges_from([(0,1),(0,2),(1,2),(2,3),(1,3)])\n",
    "\n",
    "pos = nx.spring_layout(G)\n",
    "\n",
    "nx.draw_networkx_nodes(G, pos, node_color ='lightblue')\n",
    "\n",
    "nx.draw_networkx_labels(G, pos)\n",
    "\n",
    "nx.draw_networkx_edges(G, pos, arrows=True, width=1)\n",
    "\n",
    "nx.draw_networkx_edge_labels(G, pos,edge_labels={(0,1):'4',(0,2):'1',(1,2):'2',(1,3):'2',(2,3):'3'},font_color='blue')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the flow distribution labelled in blue is a flow from 0 to 3. Indeed,\n",
    "- for the non-terminal nodes 1 and 2, the incoming flow equals the outcoming flow;\n",
    "- the total flow outcoming from 0 equals the total flow incoming to 3 (the throughput is 5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Flow - Min Cut Theorem\n",
    "It is given a graph $G = (V, E)$ which represents a flow network and two vertices source $s$ and sink $t$ in it. Every edge $(u,v)$ has a capacity $c(u,v)$. We want to find the maximum possible flow from s to t with the following constraint:\n",
    "\n",
    "1. Flow on an edge doesn’t exceed the given capacity of the edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx_nodes(G, pos, node_color ='lightblue')\n",
    "\n",
    "nx.draw_networkx_labels(G, pos)\n",
    "\n",
    "nx.draw_networkx_edges(G, pos, arrows=True, width=1)\n",
    "\n",
    "nx.draw_networkx_edge_labels(G, pos,edge_labels={(0,1):'2',(0,2):'1',(1,2):'4',(1,3):'3',(2,3):'2'},font_color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: consider the graph above with terminal nodes 0 and 3, where the red labels denote the capacity of the edge, i.e., the maximal flow that can be sent along the edge. What is the maximal flow that can be sent from 0 to 3?\n",
    "\n",
    "**Question**: give an intuitive answer on why a flow of throughput 4 cannot be sent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition (cut of a network)**: a s-t cut of the network $G=(N,E)$ is a partition of the nodes $\\{U,U^C\\}$, such that $s \\in U$ and $t \\in U_C$.\n",
    "\n",
    "We shall see that the notion of cut is strongly related to the maximal flow that can be sent in the network. The cuts of the network above are:\n",
    "- $U=\\{0,1,2\\},U^C=\\{3\\}$\n",
    "- $U=\\{0,1\\},U^C=\\{2,3\\}$\n",
    "- $U=\\{0,2\\},U^C=\\{1,3\\}$\n",
    "- $U=\\{0\\},U^C=\\{1,2,3\\}$\n",
    "\n",
    "**Definition (cut capacity)**: the capacity of a cut $\\{U,U^C\\}$ is\n",
    "$$\n",
    "C_{U} = \\sum_{i \\in U}\\sum_{j \\in U^C} c(i,j)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Max flow min cut Theorem**: the maximal flow that can be sent from $s$ to $t$ equals the minimal cut capacity among the s-t cuts of the network. \n",
    "\n",
    "**Back to the question**:\n",
    "- $U=\\{0,1,2\\},U^C=\\{3\\}$ -> $C_U = 5$\n",
    "- $U=\\{0,1\\},U^C=\\{2,3\\}$ -> $C_U = 8$\n",
    "- $U=\\{0,2\\},U^C=\\{1,3\\}$ -> $C_U = 4$\n",
    "- $U=\\{0\\},U^C=\\{1,2,3\\}$ -> $C_U = 3$\n",
    "\n",
    "**Answer**: the 0-3 min-cut has capacity 3, thus the maximal flow from 0 to 3 is 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NetworkX has many functions useful for flow applications, e.g., `networkx.algorithms.flow.maximum_flow` and `networkx.algorithms.flow.minimum_cut`, which compute the maximum throughput and the value and the node partition of a minimum cut, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find the maximal flow, the edges have to be labelled with a 'capacity' label\n",
    "# we then modify the graph in such a way to include this information \n",
    "# (check the `networkx.algorithms.flow.maximum_flow` documentation for more info)\n",
    "\n",
    "G[0][1]['capacity'] = 2\n",
    "G[0][2]['capacity'] = 1\n",
    "G[1][2]['capacity'] = 4\n",
    "G[1][3]['capacity'] = 3\n",
    "G[2][3]['capacity'] = 2\n",
    "\n",
    "nx.algorithms.flow.maximum_flow(G,0,3)\n",
    "\n",
    "# maximum_flow returns the maximal throughput, plus a dictionary containing the value of the flow that goes through each edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.algorithms.flow.minimum_cut(G,0,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intervention in capacitated networks: two dual problems\n",
    "\n",
    "### Adversarial intervention\n",
    "**Question**: suppose you are an adversarial agent that aims at minimizing the flow that can be send from 0 to 3 by removing capacity subject to a budget constraint (or even disconnect the network). \n",
    "- Where do you remove the capacity? \n",
    "- What is the minimal capacity that you need to remove in order to disconnect the network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer** \n",
    "- Since the bottleneck of the flow is the min-cut of the network, the adversary should reduce the capacity of such a  cut. Thus, in this case, the adversary should reduce capacity of edges between the sets $\\{0\\}$ and the set $\\{1,2,3\\}$, which are $(0,1)$ and $(0,2)$. \n",
    "- The minimal capacity that needs to be removed equals the capacity of the min-cut of the network, which is 3.\n",
    "\n",
    "While for this network the answer could be obvious, when the network is large the algorithms `networkx.algorithms.flow.maximum_flow` and `networkx.algorithms.flow.minimum_cut` are very useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx_nodes(G, pos, node_color ='lightblue')\n",
    "\n",
    "nx.draw_networkx_labels(G, pos)\n",
    "\n",
    "nx.draw_networkx_edges(G, pos, arrows=True, width=1)\n",
    "\n",
    "nx.draw_networkx_edge_labels(G,pos,edge_labels={(0,1):'2',\n",
    "(0,2):'1',(1,2):'4',(1,3):'3',\n",
    "(2,3):'2'},font_color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cuts**\n",
    "- $U=\\{0,1,2\\},U^C=\\{3\\}$ -> $C_U = 5$\n",
    "- $U=\\{0,1\\},U^C=\\{2,3\\}$ -> $C_U = 8$\n",
    "- $U=\\{0,2\\},U^C=\\{1,3\\}$ -> $C_U = 4$\n",
    "- $U=\\{0\\},U^C=\\{1,2,3\\}$ -> $C_U = 3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planner intervention\n",
    "**Question**: Suppose you are a planner that aims at maximing the flow that can be send from 0 to 3. Where do you allocate the capacity?\n",
    "\n",
    "**Answer**: you should allocate the capacity in such a way that the capacity of the mincut is maximized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.remove_edge(0,2)\n",
    "\n",
    "nx.draw_networkx_nodes(G, pos, node_color ='lightblue')\n",
    "\n",
    "nx.draw_networkx_labels(G, pos)\n",
    "\n",
    "nx.draw_networkx_edges(G, pos, arrows=True, width=1)\n",
    "\n",
    "nx.draw_networkx_edge_labels(G,pos,edge_labels={(0,1):'2',(1,2):'4',(1,3):'1',\n",
    "(2,3):'3'},font_color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem**: suppose you can allocate a capacity 4 (that can be distributed on several links). Where do you allocate it?\n",
    "\n",
    "**Solution**: first compute the capacity of the cuts:\n",
    "- $U=\\{0,1,2\\},U^C=\\{3\\}$ -> $C_U = 4$\n",
    "- $U=\\{0,1\\},U^C=\\{2,3\\}$ -> $C_U = 5$\n",
    "- $U=\\{0,2\\},U^C=\\{1,3\\}$ -> $C_U = 5$\n",
    "- $U=\\{0\\},U^C=\\{1,2,3\\}$ -> $C_U = 2$\n",
    "\n",
    "The min-cut is $\\{0\\},\\{1,2,3\\}$, thus the capacity should be allocated on the links between these set, i.e., on $(0,1)$.\n",
    "\n",
    "Is allocating capacity 4 on $(0,1)$ optimal? NO!\n",
    "\n",
    "In such a case, the cut capacities become:\n",
    "\n",
    "- $U=\\{0,1,2\\},U^C=\\{3\\}$ -> $C_U = 4$\n",
    "- $U=\\{0,1\\},U^C=\\{2,3\\}$ -> $C_U = 5$\n",
    "- $U=\\{0,2\\},U^C=\\{1,3\\}$ -> $C_U = 5$\n",
    "- $U=\\{0\\},U^C=\\{1,2,3\\}$ -> $C_U = 6$\n",
    "\n",
    "and the corresponding throughput is 4.\n",
    "\n",
    "Note instead that after allocating a capacity 2 on edge $(0,1)$, the cut capacities become\n",
    "\n",
    "- $U=\\{0,1,2\\},U^C=\\{3\\}$ -> $C_U = 4$\n",
    "- $U=\\{0,1\\},U^C=\\{2,3\\}$ -> $C_U = 5$\n",
    "- $U=\\{0,2\\},U^C=\\{1,3\\}$ -> $C_U = 5$\n",
    "- $U=\\{0\\},U^C=\\{1,2,3\\}$ -> $C_U = 4$,\n",
    "\n",
    "with still a capacity 2 to be allocated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx_nodes(G, pos, node_color ='lightblue')\n",
    "\n",
    "nx.draw_networkx_labels(G, pos)\n",
    "\n",
    "nx.draw_networkx_edges(G, pos, arrows=True, width=1)\n",
    "\n",
    "nx.draw_networkx_edge_labels(G,pos,edge_labels={(0,1):'4',(1,2):'4',(1,3):'1',\n",
    "(2,3):'3'},font_color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This remaining capacity should be allocated on both the first and the last cut, so the final solution is to allocate capacity 3 on the edge $(0,1)$, and 1 on the edge $(1,3)$ or $(2,3)$, which leads to cuts\n",
    "\n",
    "- $U=\\{0,1,2\\},U^C=\\{3\\}$ -> $C_U = 5$\n",
    "- $U=\\{0,1\\},U^C=\\{2,3\\}$ -> $C_U = 5$\n",
    "- $U=\\{0,2\\},U^C=\\{1,3\\}$ -> $C_U = 5$\n",
    "- $U=\\{0\\},U^C=\\{1,2,3\\}$ -> $C_U = 5$,\n",
    "\n",
    "and maximal throughput 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "In some cases, it is possible that the capacity of two min-cuts can be increased by improving only one edge.\n",
    "Consider the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_edge(0,2)\n",
    "G.remove_edge(1,3)\n",
    "\n",
    "nx.draw_networkx_nodes(G, pos, node_color ='lightblue')\n",
    "\n",
    "nx.draw_networkx_labels(G, pos)\n",
    "\n",
    "nx.draw_networkx_edges(G, pos, arrows=True, width=1)\n",
    "\n",
    "nx.draw_networkx_edge_labels(G,pos,edge_labels={(0,1):'1',(0,2):'1',(1,2):'1',\n",
    "(2,3):'3'},font_color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: what is the maximal throughput that can be sent from 0 to 3?\n",
    "\n",
    "The answer could be given by using NetworkX functions, but we do not use it now.\n",
    "\n",
    "**Answer**: we start by computing the cut capacities:\n",
    "\n",
    "- $U=\\{0,1,2\\},U^C=\\{3\\}$ -> $C_U = 3$\n",
    "- $U=\\{0,1\\},U^C=\\{2,3\\}$ -> $C_U = 2$\n",
    "- $U=\\{0,2\\},U^C=\\{1,3\\}$ -> $C_U = 4$\n",
    "- $U=\\{0\\},U^C=\\{1,2,3\\}$ -> $C_U = 2$.\n",
    "\n",
    "The maximal throughput is thus 2.\n",
    "\n",
    "**Question 2**: suppose you can allocate a capacity 1 on the network. Where do you allocate it?\n",
    "\n",
    "**Answer**: there are two mincuts, whose capacity is 2. \n",
    "- For the mincut $U=\\{0,1\\},U^C=\\{2,3\\}$,\n",
    "$$\n",
    "C_U = c(0,2) + c(1,2)\n",
    "$$ \n",
    "- For the mincut $U=\\{0\\},U^C=\\{1,2,3\\}$,\n",
    "$$\n",
    "C_U = c(0,1) + c(0,2)\n",
    "$$\n",
    "\n",
    "Note that both the capacities can be improved by adding capacity 1 to the edge $(0,2)$. By doing this, the capacities become\n",
    "\n",
    "- $U=\\{0,1,2\\},U^C=\\{3\\}$ -> $C_U = 3$\n",
    "- $U=\\{0,1\\},U^C=\\{2,3\\}$ -> $C_U = 3$\n",
    "- $U=\\{0,2\\},U^C=\\{1,3\\}$ -> $C_U = 4$\n",
    "- $U=\\{0\\},U^C=\\{1,2,3\\}$ -> $C_U = 3$,\n",
    "\n",
    "and the maximal throughput become 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, these type of considerations can be implemented algorithmically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Flow - Min Cut Theorem and Ford Fulkerson algorithm\n",
    "\n",
    "**Credits**: The code for Ford-Fulkerson Algorithm is based on material that can be found on Wikipedia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is given a graph $G = (V, E)$ which represents a flow network, and two vertices source $s$ and sink $t$ in it. Every edge $(u,v)$ has a capacity $c(u,v)$. We want to find the maximum possible flow from $s$ to $t$ with the following constraints.\n",
    "\n",
    "The desired flow $f$ is constructed iteratively starting from a zero-flow vector: at each round of the algorithm $f$ is updated in such a way that the capacity and balance constraints are not violated.\n",
    "\n",
    "To do this, at each round, given the current flow vector $f$, we define the **residual network** $G_{f}(V,E_{f})$ to be the network with capacity $c_{f}(u,v)=c(u,v)-f(u,v)$. A search on the residual graph $G_f$ is performed to find an **augmenting path** (i.e., a path on the residual network with positive capacity on every edge of the path). If an augmenting path is found, this means that the current flow $f$ on that path can be increased.\n",
    "\n",
    "### Ford–Fulkerson Algorithm \n",
    "**Inputs**: a graph $G=(V,E)$, a vector of flow capacities $c = (c(u,v))_{(u,v) \\in E}$, a source node $s$, and a sink node $t$\n",
    "\n",
    "**Output**: a flow $f = (f(u,v))_{(u,v) \\in E}$ from $s$ to $t$ of maximum throughput\n",
    "\n",
    "1. $f(u,v)\\leftarrow 0$ for all edges $(u,v)$\n",
    "2. While there is a path $p$ from $s$ to $t$ in $G_{f}$, such that $c_{f}(u,v)=c(u,v)-f(u,v)>0$ for all edges $(u,v)\\in p$:\n",
    " 1. Find $c_{f}(p)=\\min\\{c_{f}(u,v):(u,v)\\in p\\}$\n",
    " 2. For each edge $(u,v)\\in p:$\n",
    "      1. $f(u,v)\\leftarrow f(u,v)+c_{f}(p)$ (Increase the flow along the path)\n",
    "      2. $f(v,u)\\leftarrow f(v,u)-c_{f}(p)$ (Impose the symmetry of the flow)\n",
    "\n",
    "Ford-Fulkerson Algorithm is called a **method**, instead of **algorithm**, because it does not specify univocally how to select paths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: iterative Ford-Fulkerson by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "G.add_edges_from([(0,1),(0,2),(1,2),(1,3),(2,3)])\n",
    "\n",
    "pos = {0: (40, 20), 1: (60, 35), 2: (60, 5), 3: (80, 20)}\n",
    "\n",
    "labels = ['0/1000','0/1000','0/1','0/1000','0/1000']\n",
    "\n",
    "zip_operator = zip(G.edges(), labels)\n",
    "labels = dict(zip_operator)\n",
    "\n",
    "nx.draw_networkx_nodes(G, pos, node_color ='lightblue')\n",
    "\n",
    "nx.draw_networkx_labels(G, pos)\n",
    "\n",
    "nx.draw_networkx_edges(G, pos, arrows=True, width=1)\n",
    "\n",
    "nx.draw_networkx_edge_labels(G,pos,edge_labels=labels,font_color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aim at finding the maximal flow from 0 to 3.\n",
    "\n",
    "The edge labels show the flow running along the edges and the capacity of the edges.\n",
    "\n",
    "We start with flow 0 on every path.\n",
    "\n",
    "0-1-2-3, 0-1-3 and 0-2-3 are augmenting paths\n",
    "\n",
    "We arbitrarly choose to add flow on 0-1-2-3.\n",
    "\n",
    "The capacity of 0-1-2-3 is the minimal capacity of the edges in the path, which is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['1/1000','0/1000','1/1','0/1000','1/1000']\n",
    "\n",
    "colors = ['red','black','red','black','red']\n",
    "\n",
    "zip_operator = zip(G.edges(), labels)\n",
    "labels = dict(zip_operator)\n",
    "\n",
    "nx.draw_networkx_nodes(G, pos, node_color ='lightblue')\n",
    "\n",
    "nx.draw_networkx_labels(G, pos)\n",
    "\n",
    "nx.draw_networkx_edges(G, pos, arrows=True, width=1)\n",
    "\n",
    "nx.draw_networkx_edge_labels(G,pos,edge_labels=labels,font_color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We update flows:\n",
    "- $f(0,1) = 1$\n",
    "- $f(1,0) = -1$ (symmetry)\n",
    "- $f(2,3) = 1$\n",
    "- $f(3,2) = -1$ (symmetry)\n",
    "- $f(1,2) = 1$\n",
    "- $f(2,1) = -1$ (symmetry),\n",
    "\n",
    "We update the residual capacities $c_f(i,j) = c(i,j) - f(i,j)$ accordingly:\n",
    "- $c_f(0,1) = 1000-1 = 999$\n",
    "- $c_f(1,0) = 0-(-1) = 1$\n",
    "- $c_f(2,3) = 1000-1 = 999$\n",
    "- $c_f(3,2) = 0-(-1) = 1$\n",
    "- $c_f(1,2) = 1-1 = 0$\n",
    "- $c_f(2,1) = 0-(-1) = 1$.\n",
    "\n",
    "Note that edges $(1,0)$ and $(2,1)$, which are not in the original network, have now positive residual capacity, meaning that we can allocate some flow on them. Intuitively speaking, allocating some flow on $(2,1)$ means removing flow from $(1,2)$. Imposing the symmetry of the flow allows to remove flow after the allocation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now proceed to iteratively updating flows. There are three augmenting paths: 0-1-3, 0-2-3, 0-2-1-3.\n",
    "\n",
    "We arbitrarly choose to allocate flow on the path 0-2-1-3.\n",
    "\n",
    "The maximum flow that can be allocated is 1, because of the residual capacity constraint of edge  (2,1) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['1/1000','1/1000','0/1','1/1000','1/1000']\n",
    "\n",
    "colors = ['black','red','red','red','black']\n",
    "\n",
    "zip_operator = zip(G.edges(), labels)\n",
    "labels = dict(zip_operator)\n",
    "\n",
    "nx.draw_networkx_nodes(G, pos, node_color ='lightblue')\n",
    "\n",
    "nx.draw_networkx_labels(G, pos)\n",
    "\n",
    "nx.draw_networkx_edges(G, pos, arrows=True, width=1)\n",
    "\n",
    "nx.draw_networkx_edge_labels(G,pos,edge_labels=labels,font_color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 1998 steps more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['1000/1000','1000/1000','0/1','1000/1000','1000/1000']\n",
    "\n",
    "zip_operator = zip(G.edges(), labels)\n",
    "labels = dict(zip_operator)\n",
    "\n",
    "nx.draw_networkx_nodes(G, pos, node_color ='lightblue')\n",
    "\n",
    "nx.draw_networkx_labels(G, pos)\n",
    "\n",
    "nx.draw_networkx_edges(G, pos, arrows=True, width=1)\n",
    "\n",
    "nx.draw_networkx_edge_labels(G,pos,edge_labels=labels,font_color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no longer augmenting paths with residual capacity in the network.\n",
    "\n",
    "Thus, the resulting flows correspond to the maximal flow that can be sent from 0 to 3.\n",
    "\n",
    "The maximal throughput that can be sent from 0 to 3 is 2000. We can verify this by using NetworkX methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign feature 'capacity' to every edge, and use networkX method for maximum flow\n",
    "\n",
    "G[0][1]['capacity'] = 1000\n",
    "G[0][2]['capacity'] = 1000\n",
    "G[1][2]['capacity'] = 1\n",
    "G[1][3]['capacity'] = 1000\n",
    "G[2][3]['capacity'] = 1000\n",
    "\n",
    "nx.algorithms.flow.maximum_flow(G,0,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you have seen, the convergence of the Ford-Fulkerson algorithm may be slow. This depends crucially on the sequence of augmenting paths that we choose. However, the algorithm is guaranteed to converge in finite steps if the capacities are rational numbers.\n",
    "\n",
    "We draw the initial graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "G.add_edges_from([(0,1),(0,2),(1,2),(1,3),(2,3)])\n",
    "\n",
    "pos = {0: (40, 20), 1: (60, 35), 2: (60, 5), 3: (80, 20)}\n",
    "\n",
    "labels = ['0/1000','0/1000','0/1','0/1000','0/1000']\n",
    "\n",
    "zip_operator = zip(G.edges(), labels)\n",
    "labels = dict(zip_operator)\n",
    "\n",
    "nx.draw_networkx_nodes(G, pos, node_color ='lightblue')\n",
    "\n",
    "nx.draw_networkx_labels(G, pos)\n",
    "\n",
    "nx.draw_networkx_edges(G, pos, arrows=True, width=1)\n",
    "\n",
    "nx.draw_networkx_edge_labels(G,pos,edge_labels=labels,font_color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us use another sequence of augmenting paths.\n",
    "\n",
    "We start allocating flow on the path 0-1-3, with residual capacity equal to 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['1000/1000','0/1000','0/1','1000/1000','0/1000']\n",
    "\n",
    "colors = ['red','black','black','red','black']\n",
    "\n",
    "zip_operator = zip(G.edges(), labels)\n",
    "labels = dict(zip_operator)\n",
    "\n",
    "nx.draw_networkx_nodes(G, pos, node_color ='lightblue')\n",
    "\n",
    "nx.draw_networkx_labels(G, pos)\n",
    "\n",
    "nx.draw_networkx_edges(G, pos, arrows=True, width=1)\n",
    "\n",
    "nx.draw_networkx_edge_labels(G,pos,edge_labels=labels,font_color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is now only an augmenting path, which is 0-2-3, with residual capacity equal to 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['1000/1000','1000/1000','0/1','1000/1000','1000/1000']\n",
    "\n",
    "colors = ['black','red','black','black','red']\n",
    "\n",
    "zip_operator = zip(G.edges(), labels)\n",
    "labels = dict(zip_operator)\n",
    "\n",
    "nx.draw_networkx_nodes(G, pos, node_color ='lightblue')\n",
    "\n",
    "nx.draw_networkx_labels(G, pos)\n",
    "\n",
    "nx.draw_networkx_edges(G, pos, arrows=True, width=1)\n",
    "\n",
    "nx.draw_networkx_edge_labels(G,pos,edge_labels=labels,font_color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are not augmenting paths in the network, thus we have found the maximal flow in only 2 steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edmonds-Karp Algorithm\n",
    "The Edmonds–Karp algorithm is an implementation of Ford–Fulkerson method, where the search order to find augmenting paths is defined. A shortest path that has available capacity is found by a breadth-first search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "# This class represents a directed graph using adjacency matrix representation\n",
    "class Graph:\n",
    "    # __init__ is a reseved method in python classes.\n",
    "    # In object oriented terminology, it is the constructor of the class.\n",
    "    # We define a new class 'graph' instead of using the NetworkX package.\n",
    "    def __init__(self, graph): \n",
    "        # the Graph object represents the flow network and the graph\n",
    "        # attribute will be updated by the Edmonds-Karp Algorithm to \n",
    "        # represent the residual graph.\n",
    "        # Entry [u][v] of graph array stores the capacity of link (u,v).\n",
    "        self.graph = graph  \n",
    "        # Number of nodes:\n",
    "        self.ROW = len(graph)\n",
    "\n",
    "    def bfs(self, s, t, parent):\n",
    "        \"\"\"Returns true if there is a path from source 's' to sink 't' in the\n",
    "        residual graph. Also fills parent[] to store the path \"\"\"\n",
    "        # Mark all the vertices as not visited\n",
    "        visited = [False] * (self.ROW)\n",
    "\n",
    "        # Create a double-ended queue for BFS\n",
    "        queue = collections.deque()\n",
    "\n",
    "        # Mark the source node as visited and enqueue it\n",
    "        # When visited, nodes are appended \"to the right end\" of the queue.\n",
    "        queue.append(s)\n",
    "        visited[s] = True\n",
    "\n",
    "        # Standard BFS loop\n",
    "        while queue: # while there are still elements in the queue\n",
    "            # Nodes are extracted from \"the left end\" of the queue\n",
    "            u = queue.popleft()\n",
    "\n",
    "            # Get all adjacent vertices of the dequeued vertex u\n",
    "            # If an adjacent vertex has not been visited, then mark \n",
    "            # it as visited and enqueue it.\n",
    "            \n",
    "            # Enumerate() method adds a counter to an iterable\n",
    "            # to keep a count of iterations. We cycle over row\n",
    "            # u of graph array: ind is the index of the node,\n",
    "            # val is >0 if node ind is adjacent to u, i.e. if \n",
    "            # there is residual capacity on the link (u,ind),\n",
    "            # it is 0 otherwise.\n",
    "            for ind, val in enumerate(self.graph[u]): \n",
    "                if (visited[ind] == False) and (val > 0):\n",
    "                    queue.append(ind)\n",
    "                    visited[ind] = True\n",
    "                    parent[ind] = u\n",
    "\n",
    "        # If sink is reached by BFS starting from source, then return\n",
    "        # true, else return false\n",
    "        return visited[t]\n",
    "\n",
    "    # Returns the maximum flow from s to t in the given graph\n",
    "    def edmonds_karp(self, source, sink):\n",
    "        # Both max flow value and max flow vector are \n",
    "        # initialized to 0\n",
    "        max_flow = 0  \n",
    "        # initialize matrix of zeros with size ROW x ROW\n",
    "        flow = np.array([[0] * (self.ROW)] * (self.ROW))\n",
    "\n",
    "        # parent array is filled by bfs() and it is used \n",
    "        # to compute augmenting paths.\n",
    "        # It is initialized with the sentinel value -1\n",
    "        parent = [-1] * (self.ROW)\n",
    "\n",
    "        # Augment the flow while there is an augmenting path from source to sink\n",
    "        # in the residual graph\n",
    "        while self.bfs(source, sink, parent): # the algorithm stops when there are not augmenting paths from s to t\n",
    "\n",
    "            # Find the minimum residual capacity of the edges along the\n",
    "            # origin-destination path found by BFS.\n",
    "            res_capacity = float(\"Inf\")\n",
    "            # start from the endpoint of the path\n",
    "            n = sink\n",
    "            # travel the path backwards until you reach the source\n",
    "            # and update the minimal residual capacity of links\n",
    "            while n != source:\n",
    "                res_capacity = min(res_capacity, self.graph[parent[n]][n])\n",
    "                n = parent[n] \n",
    "\n",
    "            # Add the residual capacity to the maximal throughput\n",
    "            max_flow += res_capacity\n",
    "\n",
    "            # Update the flow vector by adding the residual capacity\n",
    "            # of the augmenting path to each edge in the path (to preserve\n",
    "            # symmetry, subtract it to each reverse edge).\n",
    "            # Compute the new residual network by updating\n",
    "            # the residual capacities of the edges and reverse edges\n",
    "            # along the augmenting path.\n",
    "            v = sink\n",
    "            while v != source:\n",
    "                u = parent[v]\n",
    "                flow[u][v] += res_capacity\n",
    "                flow[v][u] -= res_capacity\n",
    "                self.graph[u][v] -= res_capacity\n",
    "                self.graph[v][u] += res_capacity\n",
    "                v = parent[v]  \n",
    "            \n",
    "        return max_flow, flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.array([[0,1000,1000,0],[0,0,1,1000],[0,0,0,1000],[0,0,0,0]])\n",
    "G = Graph(W)\n",
    "\n",
    "max_flow, flow = Graph.edmonds_karp(G,0,3)\n",
    "\n",
    "print(\"The maximum flow:\", max_flow, \"\\n\")\n",
    "print(\"The flow distribution: \\n\", flow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us explore the steps of the algorithm by adding some print in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph_print:\n",
    "    # __init__ is a reseved method in python classes.\n",
    "    # In object oriented terminology, it is the constructor of the class.\n",
    "    # We define a new class 'graph' instead of using the NetworkX package.\n",
    "    def __init__(self, graph): \n",
    "        # the Graph object represents the flow network and the graph\n",
    "        # attribute will be updated by the Edmonds-Karp Algorithm to \n",
    "        # represent the residual graph.\n",
    "        # Entry [u][v] of graph array stores the capacity of link (u,v).\n",
    "        self.graph = graph  \n",
    "        # Number of nodes:\n",
    "        self.ROW = len(graph)\n",
    "\n",
    "    def bfs(self, s, t, parent):\n",
    "        \"\"\"Returns true if there is a path from source 's' to sink 't' in the\n",
    "        residual graph. Also fills parent[] to store the path \"\"\"\n",
    "        # Mark all the vertices as not visited\n",
    "        visited = [False] * (self.ROW)\n",
    "\n",
    "        # Create a double-ended queue for BFS\n",
    "        queue = collections.deque()\n",
    "\n",
    "        # Mark the source node as visited and enqueue it\n",
    "        # When visited, nodes are appended \"to the right end\" of the queue.\n",
    "        queue.append(s)\n",
    "        visited[s] = True\n",
    "\n",
    "        # Standard BFS loop\n",
    "        while queue: # while there are still elements in the queue\n",
    "            # Nodes are extracted from \"the left end\" of the queue\n",
    "            print(\"Queue:\", queue, \"\\n\")\n",
    "            u = queue.popleft()\n",
    "            print(\"Extracted node:\", u, \"\\n\")\n",
    "\n",
    "            # Get all adjacent vertices of the dequeued vertex u\n",
    "            # If an adjacent vertex has not been visited, then mark \n",
    "            # it as visited and enqueue it.\n",
    "            \n",
    "            # Enumerate() method adds a counter to an iterable\n",
    "            # to keep a count of iterations. We cycle over row\n",
    "            # u of graph array: ind is the index of the node,\n",
    "            # val is >0 if node ind is adjacent to u, i.e. if \n",
    "            # there is residual capacity on the link (u,ind),\n",
    "            # it is 0 otherwise.\n",
    "            for ind, val in enumerate(self.graph[u]): \n",
    "                if (visited[ind] == False) and (val > 0):\n",
    "                    queue.append(ind)\n",
    "                    visited[ind] = True\n",
    "                    parent[ind] = u\n",
    "            \n",
    "            print(\"Parents\", parent, \"\\n\")\n",
    "            print(\"Visited\", visited, \"\\n \\n \\n\")\n",
    "\n",
    "        # If sink is reached by BFS starting from source, then return\n",
    "        # true, else return false\n",
    "        return visited[t]\n",
    "\n",
    "    # Returns the maximum flow from s to t in the given graph\n",
    "    def edmonds_karp(self, source, sink):\n",
    "        n_iter = 1\n",
    "        print(\"iteration of bfs number:\", n_iter, \"\\n\")\n",
    "        # parent array is filled by bfs() and it is used \n",
    "        # to compute augmenting paths.\n",
    "        # It is initialized with the sentinel value -1\n",
    "        # If parent[j] == -1, node 'j' has not been visited yet\n",
    "        parent = [-1] * (self.ROW)\n",
    "\n",
    "        # Both max flow value and max flow vector are \n",
    "        # initialized to 0\n",
    "        max_flow = 0  \n",
    "        # initialize matrix of zeros with size ROW x ROW\n",
    "        flow = np.array([[0] * (self.ROW)] * (self.ROW))\n",
    "\n",
    "        # Augment the flow while there is a path from source to sink\n",
    "        # in the residual graph\n",
    "        while self.bfs(source, sink, parent): # the algorithm stops when there are not augmenting paths from s to t\n",
    "            # now parent stores the augmenting path found by bfs\n",
    "\n",
    "            # Find the minimum residual capacity of the edges along the\n",
    "            # origin-destination path found by BFS.\n",
    "            res_capacity = float(\"Inf\")\n",
    "            # start from the endpoint of the path\n",
    "            n = sink\n",
    "            # travel the path backwards until you reach the source\n",
    "            # and update the minimal residual capacity of links\n",
    "            while n != source:\n",
    "                res_capacity = min(res_capacity, self.graph[parent[n]][n])\n",
    "                n = parent[n] \n",
    "\n",
    "            # Add the residual capacity to the maximal throughput\n",
    "            max_flow += res_capacity\n",
    "\n",
    "            # Update the flow vector by adding the residual capacity\n",
    "            # of the augmenting path to each edge in the path (to preserve\n",
    "            # symmetry, subtract it to each reverse edge).\n",
    "            # Compute the new residual network by updating\n",
    "            # the residual capacities of the edges and reverse edges\n",
    "            # along the augmenting path.\n",
    "            v = sink\n",
    "            while v != source:\n",
    "                u = parent[v]\n",
    "                flow[u][v] += res_capacity\n",
    "                flow[v][u] -= res_capacity\n",
    "                self.graph[u][v] -= res_capacity\n",
    "                self.graph[v][u] += res_capacity\n",
    "                v = parent[v]  \n",
    "            n_iter += 1\n",
    "            print(\"iteration of bfs number:\", n_iter, \"\\n\")\n",
    "            \n",
    "        return max_flow, flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.array([[0,1000,1000,0],[0,0,1,1000],[0,0,0,1000],[0,0,0,0]])\n",
    "G = Graph_print(W)\n",
    "\n",
    "max_flow, flow = Graph_print.edmonds_karp(G,0,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Networkx implements the Edmonds-Karp algorithm. \n",
    "\n",
    "The `networkx.algorithms.flow.edmonds_karp` function returns the residual network resulting after computing the maximum flow.\n",
    "\n",
    "Networkx also provides the functions `networkx.algorithms.flow.maximum_flow` and `networkx.algorithms.flow.minimum_cut` which compute the maximun throughput and  the value and the node partition of a minimum cut, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi origin-destination maxflow\n",
    "\n",
    "So far, we have studied maximum flow problems when there is a single origin-destination pair. \n",
    "\n",
    "For some applications, it is useful to find maximum flow with multiple origin-destinations.\n",
    "\n",
    "The multi o-d maxflow problem may be rephrased in terms of single o-d maxflow problem, and then handled with the standard tools. Let us see this by an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "G.add_edges_from([(0,2),(0,1),(2,4),(1,3),(2,5),(3,4),(4,5),(1,4),(1,5)])\n",
    "\n",
    "pos = {0: [0,2], 1: [1,0], 2: [1,3], 3: [3,0], 4: [3,2], 5:[1,2] }\n",
    "\n",
    "nx.draw_networkx_nodes(G, pos, node_color ='lightblue')\n",
    "\n",
    "nx.draw_networkx_labels(G, pos)\n",
    "\n",
    "nx.draw_networkx_edges(G, pos, arrows=True, width=1)\n",
    "\n",
    "nx.draw_networkx_edge_labels(G,pos,edge_labels={(0,1):'4',\n",
    "(0,2):'6',(2,4):'2',(2,5):'5',\n",
    "(3,4):'6', (4,5):'1', (1,3):'2', (1,4):'3', (1,5): ' 5'},font_color='blue')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider sources $\\{0,1\\}$ and sinks $\\{4,5\\}$. To reconduct the problem to a single source and sink, an equivalent problem is to add an additional pair of nodes $S$ and $T$, and add edges from $S$ to every source of the original network, and from every sink of the original network to $T$, with infinite capacity.\n",
    "\n",
    "For simplicity, let us call 6 and 7 the new nodes.\n",
    "\n",
    "We define the resulting network for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = nx.DiGraph()\n",
    "G1.add_edges_from([(0,2),(0,1),(2,4),(1,3),(2,5),(3,4),(4,5),(1,4),(1,5)])\n",
    "\n",
    "# add additional nodes and edges\n",
    "G1.add_edges_from([(6,0),(6,1),(4,7),(5,7)])\n",
    "\n",
    "# define position for the two new nodes\n",
    "pos = {0: [0,2], 1: [1,0], 2: [1,3], 3: [3,0], 4: [3,2], 5:[1,2], 6:[-1,1], 7:[2,0.5]}\n",
    "\n",
    "nx.draw_networkx_nodes(G1, pos, node_color ='lightblue')\n",
    "\n",
    "nx.draw_networkx_labels(G1, pos)\n",
    "\n",
    "nx.draw_networkx_edges(G1, pos, arrows=True, width=1)\n",
    "\n",
    "nx.draw_networkx_edge_labels(G,pos,edge_labels={(0,1):'4',\n",
    "(0,2):'6',(2,4):'2',(2,5):'5',\n",
    "(3,4):'6', (4,5):'1', (1,3):'2', (1,4):'3', (1,5): ' 5',\n",
    "(6,0):'inf',(6,1):'inf',(4,7):'inf',(5,7):'inf'},font_color='blue')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proposition**: the max-flow in the new network with source S and sink T is equivalent to the max-flow of the original problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the capacities, and use NetworkX algorithms to compute maximum flow\n",
    "\n",
    "G1[0][2]['capacity'] = 6\n",
    "G1[0][1]['capacity'] = 4\n",
    "G1[2][4]['capacity'] = 4\n",
    "G1[2][5]['capacity'] = 5\n",
    "G1[3][4]['capacity'] = 6\n",
    "G1[4][5]['capacity'] = 1\n",
    "G1[1][3]['capacity'] = 2\n",
    "G1[1][4]['capacity'] = 3\n",
    "G1[1][5]['capacity'] = 5\n",
    "\n",
    "# call S = 6, and T = 7, and assign infinite capacity\n",
    "G1[6][0]['capacity'] = float('inf')\n",
    "G1[6][1]['capacity'] = float('inf')\n",
    "G1[4][7]['capacity'] = float('inf')\n",
    "G1[5][7]['capacity'] = float('inf')\n",
    "\n",
    "nx.algorithms.flow.maximum_flow(G1,6,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute also the minimum cut\n",
    "nx.algorithms.flow.minimum_cut(G1,6,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the minimum cut equals the maximal flow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application of multi o-d maxflow problems: perfect matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition**: given a graph $G=(V,E)$, a matching is a subset of edges $M \\subseteq E$ such that no edges in $M$ share a common node (head or tail).\n",
    "\n",
    "**Definition**: Consider a simple bipartite graph, whereby the node set can be partitioned as $V = V_0 \\cup V_1$, with $V_0 \\cap V_1 = \\emptyset$, and no edges between nodes of the same set exist. For $h = 0,1$, we shall refer to a matching $M$ in $G$ as $V_h$-perfect (or $V_h$-saturating) if every node in $V_h$ is matched in $M$.\n",
    "\n",
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_edges_from([(0,2),(0,3),(1,3),(1,4)])\n",
    "\n",
    "pos = {0:[0,2], 1:[0,0], 2:[2,3], 3:[2,1], 4:[2,-1]}\n",
    "\n",
    "nx.draw(G, pos, with_labels=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We immediately observe that the graph is bipartite, with $V_0 = \\{0,1\\}, V_1 = \\{2,3,4\\}$.\n",
    "\n",
    "We now provide a $V_0$-perfect matching, i.e., a matching that matches every node in $V_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_edges_from([(0,2),(1,3)])\n",
    "G.add_node(4)\n",
    "\n",
    "pos = {0:[0,2], 1:[0,0], 2:[2,3], 3:[2,1], 4:[2,-1]}\n",
    "\n",
    "nx.draw(G, pos, with_labels=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: can you find a $V_1$ perfect matching?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hall's marriage Theorem**: for a simple bipartite graph $G = (V,E)$ and $V_0 \\subseteq V$, there exists a $V_0$-perfect matching in $G$ if and only if\n",
    "\n",
    "$$\n",
    "|\\mathcal{U}| \\le |\\mathcal{N}_{\\mathcal{U}}| \\quad \\forall \\mathcal{U} \\subseteq V_0,\n",
    "$$\n",
    "\n",
    "where $\\mathcal{N}_{\\mathcal{U}}$ is the neighborhood of $\\mathcal{U}$ in $G$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, for every subset $U$ of $V_0$, we require that $U$ possesses a number of neighboring nodes which is at least the number of nodes in $U$. The necessity of such condition is trivial to verify, for the sufficiency we refer to the lecture notes.\n",
    "\n",
    "We here focus on the algorithmic viewpoint of matching problems and on applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: assume there are 5 people and 5 books (with one copy of each book), and each person expresses interest in some of the books. Is there a way to assign to every person a book of interest?\n",
    "\n",
    "We can represent this situation by a simple bipartite network, where $V_0$ is the set of people and $V_1$ and the set of books, and an edge $(n_0,n_1)$ (with $n_0 \\in V_0$, $n_1 \\in V_1$) exists if the person $n_0$ is interested in the book $n_1$. \n",
    "\n",
    "The question may be rephrased in: \"does a $V_0$-perfect matching exist?\" \n",
    "\n",
    "If there are less books than people, i.e., if $|V_1|<|V_0|$, a $V_0$-perfect matching cannot exist. This follows immediately from Hall's theorem by taking $\\mathcal{U}=V_0$, and observing that $N_{\\mathcal{U}} \\subseteq V_1$.\n",
    "\n",
    "**Remark**: Note that a perfect matching (both for $V_0$ and $V_1$) can exist only if $|V_0|=|V_1|$.\n",
    "\n",
    "We consider a simple bipartite network, and try a naive algorithm to answer the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_edges_from([(0,6),(0,7),(1,6),(1,7),(1,8),(2,5),(2,6),(2,7),(2,9),(3,7),(4,7),(4,8),(4,9)])\n",
    "\n",
    "pos = {0:[0,2], 1:[0,1], 2:[0,0], 3:[0,-1], 4:[0,-2], 5:[1,2], 6:[1,1], 7:[1,0], 8:[1,-1], 9:[1,-2]}\n",
    "\n",
    "nx.draw(G,pos, with_labels=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We let the left nodes be people, and the right nodes be books. You can verify that the graph is bipartite.\n",
    "\n",
    "We try this greedy algorithm: for every person (from above to below) we assign the first book (from above to below) of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign book 6 to person 0\n",
    "for u,v in G.edges():\n",
    "    G[u][v]['color'] = 'black'\n",
    "    \n",
    "G[0][6]['color'] = 'red'\n",
    "\n",
    "colors = [G[u][v]['color'] for u,v in G.edges()]\n",
    "\n",
    "nx.draw(G, pos, with_labels = True, edge_color = colors)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Book 6 is not available for person 1, thus assign book 7\n",
    "G[1][7]['color'] = 'blue'\n",
    "\n",
    "colors = [G[u][v]['color'] for u,v in G.edges()]\n",
    "\n",
    "nx.draw(G, pos, with_labels = True, edge_color = colors)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign book 5 to person 2\n",
    "G[2][5]['color'] = 'green'\n",
    "\n",
    "colors = [G[u][v]['color'] for u,v in G.edges()]\n",
    "\n",
    "nx.draw(G, pos, with_labels = True, edge_color = colors)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Node 3 is not matched! The greedy algorithm fails in finding a perfect matching. \n",
    "\n",
    "However, this does not mean that a perfect matching does not exist. To verify that a perfect matching exists, one could verify the sufficient and necessary condition in Hall's marriage theorem. \n",
    "\n",
    "We instead show an analogy between maximal flows and perfect matching, and exploit such an analogy to find perfect matching by Ford-Fulkerson theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a simple bipartite graph $G=(V,E)$, consider the directed capacitated graph $G1$, with node set $V \\cup s \\cup t$, and edge set constructed as follows:\n",
    "- for every node $n \\in V_0$, add an edge (s,n), with capacity 1;\n",
    "- for every node $n \\in V_1$, add an edge (n,t), with capacity 1;\n",
    "- for every undirected edge $(i,j)$ in $G$, add a directed edge $(i,j)$ in $G1$ with capacity 1.\n",
    "\n",
    "Let us construct $G1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = nx.DiGraph()\n",
    "G1.add_edges_from([(0,6),(0,7),(1,6),(1,7),(1,8),(2,5),(2,6),(2,7),(2,9),(3,7),(4,7),(4,8),(4,9)])\n",
    "G1.add_edges_from([(10,0),(10,1),(10,2),(10,3),(10,4),(5,11),(6,11),(7,11),(8,11),(9,11)])\n",
    "\n",
    "pos = {0:[0,2], 1:[0,1], 2:[0,0], 3:[0,-1], 4:[0,-2], 5:[1,2], 6:[1,1], 7:[1,0], 8:[1,-1], 9:[1,-2], 10:[-1,0], 11:[2,0]}\n",
    "\n",
    "nx.draw(G1,pos,with_labels=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an analogy between perfect matchings and maximal flow on this auxiliary network $G1$. In particular, a $V_0$-perfect matching on $G$ exists if and only if it there exists a flow with throughput $|V_0|$ on the network $G1$. We can now exploit Ford-Fulkerson algorithm to find the maximum flow that can be sent in $G1$.\n",
    "\n",
    "**Remark**: the analogy can be proved by using the fact that, if the capacities of the edges are integers, then the maximum flow has integer components (see the lecture notes). Because of the network structure, if a maximum flow with throughput $|V_0|$ exists, then every node in $V_0$ has incoming and outcoming flow $1$, since all the edges have unitary capacity. Moreover, given a node $i \\in |V_0|$, if a $|V_0|$-perfect matching exists, then there exists $k \\in V_1$ such that\n",
    "\n",
    "$$\n",
    "f_{(i,j)} = \n",
    "\\begin{cases}\n",
    "1 \\quad \\text{if} \\ j = k \\\\\n",
    "0 \\quad \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Thus, given a maximum flow with throughput $|V_0|$, the associated $V_0$-perfect matching can be found by selecting all the edges $(i,j)$ ($i \\in V_0, j \\in V_1$) such that $f_{(i,j)}=1$.\n",
    "\n",
    "**Exercise**: find the maximum flow on $G1$, and deduce the perfect matching on $G$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise Katz centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = nx.adjacency_matrix(G)\n",
    "W = W.toarray()\n",
    "\n",
    "# compute the largest eigenvalue of W\n",
    "w,v = np.linalg.eig(W)\n",
    "w = w.real\n",
    "\n",
    "lambda_max = max(w) \n",
    "\n",
    "beta = 0.15\n",
    "mu = np.ones((N,1))\n",
    "\n",
    "z_0 = np.ones((N,1))/N\n",
    "# set a tolerance to assess convergence to the limit\n",
    "tol = 1e-5\n",
    "# evolve the dynamics\n",
    "z_old = z_0\n",
    "\n",
    "while True:\n",
    "    z_new = W.T @ z_old * (1-beta)/lambda_max + beta * mu\n",
    "    if np.linalg.norm(z_new-z_old) < tol:\n",
    "        break\n",
    "    z_old=z_new\n",
    "\n",
    "zk_approx = z_new\n",
    "\n",
    "# normalize the centrality\n",
    "zk_approx = zk_approx / sum(zk_approx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise speed of convergence Bonacich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(16,7))\n",
    "\n",
    "# set 3 iteration numbers\n",
    "iters = [10,15,50]\n",
    "# define the position of the next plot in the subplot grid\n",
    "position = 1\n",
    "# create a list to collect the page rank values obtained in the three runs \n",
    "prvals = []\n",
    "\n",
    "for max_iter in iters:\n",
    "    # compute page rank\n",
    "    z_0 = np.ones((N,1))/N\n",
    "    z_old = z_0\n",
    "    \n",
    "    while True:\n",
    "        z_new = P.T @ z_old * (1-beta) + beta * mu\n",
    "        if np.linalg.norm(z_new-z_old) < tol:\n",
    "            break\n",
    "        z_old=z_new\n",
    "\n",
    "    pr = z_new\n",
    "\n",
    "    # normalize the centrality\n",
    "    prval = pr / sum(pr)\n",
    "    \n",
    "    # append the result to the list\n",
    "    prvals.append(np.array(prval)) \n",
    "    # create a new sublot in the grid\n",
    "    ax = fig.add_subplot(2,2,position)\n",
    "    # plot the PR values\n",
    "    ax.plot(prval, color=np.random.rand(3), label='{0:d} iterations'.format(max_iter))\n",
    "    position+=1\n",
    "\n",
    "# add a legend which contains all label\n",
    "# informations specified in previous plot calls\n",
    "fig.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
